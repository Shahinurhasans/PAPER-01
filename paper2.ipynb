{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd6840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENHANCED WSI FEATURE EXTRACTION FRAMEWORK\n",
      "Features: Multi-Seed Stability | Uncertainty Quantification | Heterogeneity\n",
      "================================================================================\n",
      "Device: cpu\n",
      "Multi-seed sampling: 5 seeds\n",
      "Output: ENHANCED_WSI_FRAMEWORK\n",
      "\n",
      "  Loading CTransPath model...\n",
      "    ✅ CTransPath checkpoint loaded\n",
      "\n",
      "================================================================================\n",
      "STEP 1: ENHANCED FEATURE EXTRACTION\n",
      "================================================================================\n",
      "\n",
      "[1/10] YG_P8W7SBCME4VH_wsi.svs\n",
      "  Seed 1/5: 42\n",
      "  Adaptive sampling: 200 initial → 1000 final\n",
      "  ❌ Insufficient tiles for seed 42\n",
      "  Seed 2/5: 123\n",
      "  Adaptive sampling: 200 initial → 1000 final\n",
      "  ❌ Insufficient tiles for seed 123\n",
      "  Seed 3/5: 456\n",
      "  Adaptive sampling: 200 initial → 1000 final\n",
      "  ❌ Insufficient tiles for seed 456\n",
      "  Seed 4/5: 789\n",
      "  Adaptive sampling: 200 initial → 1000 final\n",
      "  ❌ Insufficient tiles for seed 789\n",
      "  Seed 5/5: 1011\n",
      "  Adaptive sampling: 200 initial → 1000 final\n",
      "  ❌ Insufficient tiles for seed 1011\n",
      "  ❌ Failed to extract features across seeds\n",
      "[2/10] YG_3OAF908JG3XG_wsi.svs\n",
      "  Seed 1/5: 42\n",
      "  Adaptive sampling: 200 initial → 1000 final\n",
      "  ❌ Insufficient tiles for seed 42\n",
      "  Seed 2/5: 123\n",
      "  Adaptive sampling: 200 initial → 1000 final\n",
      "  ❌ Insufficient tiles for seed 123\n",
      "  Seed 3/5: 456\n",
      "  Adaptive sampling: 200 initial → 1000 final\n",
      "  ❌ Insufficient tiles for seed 456\n",
      "  Seed 4/5: 789\n",
      "  Adaptive sampling: 200 initial → 1000 final\n",
      "  ❌ Insufficient tiles for seed 789\n",
      "  Seed 5/5: 1011\n",
      "  Adaptive sampling: 200 initial → 1000 final\n",
      "  ❌ Insufficient tiles for seed 1011\n",
      "  ❌ Failed to extract features across seeds\n",
      "[3/10] YG_30TUKBI1ZXBK_wsi.svs\n",
      "  Seed 1/5: 42\n",
      "  Adaptive sampling: 200 initial → 1000 final\n",
      "  ❌ Insufficient tiles for seed 42\n",
      "  Seed 2/5: 123\n",
      "  Adaptive sampling: 200 initial → 1000 final\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ENHANCED CTRANSPATH PIPELINE WITH ADVANCED EVALUATION METRICS\n",
    "# Multi-Seed Stability | Uncertainty Quantification | Heterogeneity Analysis\n",
    "# Patch Quality Control | Adaptive Sampling | Cross-Encoder Fusion\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from skimage.filters import threshold_otsu, laplace, gaussian\n",
    "from skimage.morphology import (remove_small_objects, binary_dilation, binary_erosion, disk)\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.color import rgb2hsv, rgb2gray\n",
    "from skimage.measure import regionprops, label\n",
    "from scipy.ndimage import distance_transform_edt, maximum_filter\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy import stats\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import timm\n",
    "import traceback\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===============================\n",
    "# REPRODUCIBILITY\n",
    "# ===============================\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "SVS_DIR = r\"C:\\Users\\Shahinur\\Downloads\\PKG_Dataset\\PKG - Brain-Mets-Lung-MRI-Path-Segs_histopathology images\\data\"\n",
    "CTRANSPATH_WEIGHTS = r\"D:\\paper\\weights\\ctranspath.pth\"\n",
    "OUTPUT_DIR = \"ENHANCED_WSI_FRAMEWORK\"\n",
    "FIGURES_DIR = f\"{OUTPUT_DIR}/evaluation_figures\"\n",
    "Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "Path(FIGURES_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Enhanced configuration\n",
    "MULTI_SEED_SAMPLING = [42, 123, 456, 789, 1011]  # 5 seeds for stability\n",
    "PATCH_SIZE = 224\n",
    "TARGET_PATCHES = 1000\n",
    "\n",
    "# Matplotlib settings\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ENHANCED WSI FEATURE EXTRACTION FRAMEWORK\")\n",
    "print(\"Features: Multi-Seed Stability | Uncertainty Quantification | Heterogeneity\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Multi-seed sampling: {len(MULTI_SEED_SAMPLING)} seeds\")\n",
    "print(f\"Output: {OUTPUT_DIR}\\n\")\n",
    "\n",
    "def log_msg(m):\n",
    "    print(m)\n",
    "    try:\n",
    "        with open(f\"{OUTPUT_DIR}/progress.log\", 'a') as f:\n",
    "            f.write(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {m}\\n\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# ============================================================\n",
    "# ADVANCED PATCH QUALITY CONTROL MODULE (NOVELTY 1)\n",
    "# ============================================================\n",
    "class AdvancedPatchQC:\n",
    "    \"\"\"\n",
    "    Multi-factor patch quality scoring combining:\n",
    "    - Tissue content\n",
    "    - Focus quality\n",
    "    - Artifact detection\n",
    "    - Information content\n",
    "    - Representativeness\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.weights = {\n",
    "            'tissue': 0.25,\n",
    "            'focus': 0.20,\n",
    "            'artifact': 0.20,\n",
    "            'information': 0.20,\n",
    "            'representativeness': 0.15\n",
    "        }\n",
    "    \n",
    "    def tissue_score(self, patch, mask):\n",
    "        \"\"\"Tissue content percentage\"\"\"\n",
    "        return mask.sum() / mask.size\n",
    "    \n",
    "    def focus_score(self, patch):\n",
    "        \"\"\"Blur detection using Laplacian variance\"\"\"\n",
    "        gray = rgb2gray(patch)\n",
    "        lap_var = laplace(gray).var()\n",
    "        # Normalize to 0-1 range\n",
    "        return min(1.0, lap_var / 100.0)\n",
    "    \n",
    "    def artifact_score(self, patch):\n",
    "        \"\"\"Detect pen marks, dust, folds\"\"\"\n",
    "        hsv = rgb2hsv(patch)\n",
    "        \n",
    "        # Pen mark detection (blue/green)\n",
    "        pen_mask = (hsv[:,:,0] > 0.4) & (hsv[:,:,0] < 0.7) & (hsv[:,:,1] > 0.5)\n",
    "        pen_ratio = pen_mask.sum() / pen_mask.size\n",
    "        \n",
    "        # Edge density (folds create many edges)\n",
    "        gray = rgb2gray(patch)\n",
    "        edges = cv2.Canny((gray * 255).astype(np.uint8), 50, 150)\n",
    "        edge_density = edges.sum() / edges.size\n",
    "        \n",
    "        # High edge density or pen marks reduce score\n",
    "        artifact_penalty = pen_ratio * 0.5 + min(edge_density / 0.1, 1.0) * 0.5\n",
    "        return max(0, 1.0 - artifact_penalty)\n",
    "    \n",
    "    def information_score(self, patch):\n",
    "        \"\"\"Entropy and edge density\"\"\"\n",
    "        gray = rgb2gray(patch)\n",
    "        \n",
    "        # Histogram entropy\n",
    "        hist, _ = np.histogram(gray, bins=32, range=(0, 1))\n",
    "        hist = hist / (hist.sum() + 1e-8)\n",
    "        entropy = -np.sum(hist * np.log(hist + 1e-8))\n",
    "        entropy_norm = entropy / np.log(32)  # Normalize by max entropy\n",
    "        \n",
    "        # Edge density (moderate is good)\n",
    "        edges = cv2.Canny((gray * 255).astype(np.uint8), 50, 150)\n",
    "        edge_density = edges.sum() / edges.size\n",
    "        edge_score = min(edge_density / 0.05, 1.0)  # Peak at 5% edges\n",
    "        \n",
    "        return 0.7 * entropy_norm + 0.3 * edge_score\n",
    "    \n",
    "    def representativeness_score(self, patch, slide_color_centroid):\n",
    "        \"\"\"Distance to slide color centroid\"\"\"\n",
    "        if slide_color_centroid is None:\n",
    "            return 0.5\n",
    "        \n",
    "        # Compute patch color centroid\n",
    "        patch_centroid = patch.reshape(-1, 3).mean(axis=0)\n",
    "        \n",
    "        # Euclidean distance in RGB space\n",
    "        distance = np.linalg.norm(patch_centroid - slide_color_centroid)\n",
    "        \n",
    "        # Convert to similarity score (closer is better)\n",
    "        return np.exp(-distance / 50.0)\n",
    "    \n",
    "    def compute_quality_score(self, patch, mask, slide_color_centroid=None):\n",
    "        \"\"\"Aggregate quality score\"\"\"\n",
    "        scores = {\n",
    "            'tissue': self.tissue_score(patch, mask),\n",
    "            'focus': self.focus_score(patch),\n",
    "            'artifact': self.artifact_score(patch),\n",
    "            'information': self.information_score(patch),\n",
    "            'representativeness': self.representativeness_score(patch, slide_color_centroid)\n",
    "        }\n",
    "        \n",
    "        # Weighted average\n",
    "        total_score = sum(scores[k] * self.weights[k] for k in scores)\n",
    "        \n",
    "        return total_score, scores\n",
    "\n",
    "# ============================================================\n",
    "# ADAPTIVE SAMPLING MODULE (NOVELTY 2)\n",
    "# ============================================================\n",
    "class AdaptiveSampler:\n",
    "    \"\"\"\n",
    "    Content-aware adaptive sampling:\n",
    "    1. Initial random sampling\n",
    "    2. Cluster into groups\n",
    "    3. Sample proportionally to cluster importance\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_initial=200, n_final=1000, n_clusters=5):\n",
    "        self.n_initial = n_initial\n",
    "        self.n_final = n_final\n",
    "        self.n_clusters = n_clusters\n",
    "    \n",
    "    def sample(self, slide_path, tissue_mask, patch_size=224):\n",
    "        \"\"\"Adaptive sampling strategy\"\"\"\n",
    "        log_msg(f\"  Adaptive sampling: {self.n_initial} initial → {self.n_final} final\")\n",
    "        \n",
    "        # Step 1: Initial uniform random sampling\n",
    "        initial_patches, initial_coords = self._uniform_sample(\n",
    "            slide_path, tissue_mask, self.n_initial, patch_size\n",
    "        )\n",
    "        \n",
    "        if len(initial_patches) < self.n_initial // 2:\n",
    "            return initial_patches, initial_coords\n",
    "        \n",
    "        # Step 2: Cluster based on color features\n",
    "        color_features = np.array([p.reshape(-1, 3).mean(axis=0) for p in initial_patches])\n",
    "        \n",
    "        if len(color_features) < self.n_clusters:\n",
    "            return initial_patches, initial_coords\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(color_features)\n",
    "        \n",
    "        # Step 3: Compute cluster importance\n",
    "        cluster_importance = self._compute_cluster_importance(\n",
    "            color_features, cluster_labels, kmeans.cluster_centers_\n",
    "        )\n",
    "        \n",
    "        # Step 4: Sample remaining patches proportionally\n",
    "        remaining = self.n_final - len(initial_patches)\n",
    "        if remaining > 0:\n",
    "            additional_patches, additional_coords = self._proportional_sample(\n",
    "                slide_path, tissue_mask, cluster_importance, \n",
    "                initial_coords, remaining, patch_size\n",
    "            )\n",
    "            \n",
    "            initial_patches.extend(additional_patches)\n",
    "            initial_coords.extend(additional_coords)\n",
    "        \n",
    "        return initial_patches[:self.n_final], initial_coords[:self.n_final]\n",
    "    \n",
    "    def _uniform_sample(self, slide_path, tissue_mask, n_samples, patch_size):\n",
    "        \"\"\"Uniform random sampling - MEMORY EFFICIENT VERSION\"\"\"\n",
    "        sl = openslide.OpenSlide(slide_path)\n",
    "        lv = sl.get_best_level_for_downsample(1)\n",
    "        ds = sl.level_downsamples[lv]\n",
    "        w, h = sl.level_dimensions[lv]\n",
    "        \n",
    "        patches, coords = [], []\n",
    "        \n",
    "        # CRITICAL FIX: Downsample tissue mask to prevent memory overflow\n",
    "        # Tissue mask might be too large, work with downsampled version\n",
    "        mask_h, mask_w = tissue_mask.shape\n",
    "        \n",
    "        # If mask is larger than level dimensions, downsample it\n",
    "        if mask_h > h or mask_w > w:\n",
    "            scale_h = h / mask_h\n",
    "            scale_w = w / mask_w\n",
    "            tissue_mask_scaled = cv2.resize(\n",
    "                tissue_mask.astype(np.uint8),\n",
    "                (w, h),\n",
    "                interpolation=cv2.INTER_NEAREST\n",
    "            ).astype(bool)\n",
    "        else:\n",
    "            tissue_mask_scaled = tissue_mask\n",
    "        \n",
    "        # Further downsample for coordinate extraction (4x smaller)\n",
    "        small_h, small_w = tissue_mask_scaled.shape[0]//4, tissue_mask_scaled.shape[1]//4\n",
    "        tissue_mask_small = cv2.resize(\n",
    "            tissue_mask_scaled.astype(np.uint8),\n",
    "            (small_w, small_h),\n",
    "            interpolation=cv2.INTER_NEAREST\n",
    "        ).astype(bool)\n",
    "        \n",
    "        # Get tissue coordinates from small mask\n",
    "        tissue_coords = np.argwhere(tissue_mask_small > 0)\n",
    "        \n",
    "        if len(tissue_coords) == 0:\n",
    "            sl.close()\n",
    "            return patches, coords\n",
    "        \n",
    "        # Random sampling\n",
    "        np.random.shuffle(tissue_coords)\n",
    "        \n",
    "        attempts = 0\n",
    "        max_attempts = min(len(tissue_coords), n_samples * 10)\n",
    "        \n",
    "        for coord in tissue_coords[:max_attempts]:\n",
    "            if len(patches) >= n_samples:\n",
    "                break\n",
    "            \n",
    "            # Scale coordinates back up (4x)\n",
    "            y, x = coord[0] * 4, coord[1] * 4\n",
    "            \n",
    "            # Check bounds\n",
    "            if y + patch_size > h or x + patch_size > w:\n",
    "                continue\n",
    "            \n",
    "            attempts += 1\n",
    "            \n",
    "            try:\n",
    "                patch = np.array(sl.read_region(\n",
    "                    (int(x*ds), int(y*ds)), lv, (patch_size, patch_size)\n",
    "                ).convert(\"RGB\"))\n",
    "                \n",
    "                # Quality checks\n",
    "                if np.mean(patch) < 220:  # Not background\n",
    "                    patches.append(patch)\n",
    "                    coords.append((x, y))\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        sl.close()\n",
    "        return patches, coords\n",
    "    \n",
    "    def _compute_cluster_importance(self, features, labels, centers):\n",
    "        \"\"\"Compute importance score for each cluster\"\"\"\n",
    "        importance = np.zeros(self.n_clusters)\n",
    "        \n",
    "        for i in range(self.n_clusters):\n",
    "            cluster_mask = labels == i\n",
    "            if cluster_mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            cluster_features = features[cluster_mask]\n",
    "            \n",
    "            # Factor 1: Cluster size (coverage)\n",
    "            size_score = cluster_mask.sum() / len(labels)\n",
    "            \n",
    "            # Factor 2: Cluster variance (heterogeneity)\n",
    "            variance_score = np.var(cluster_features, axis=0).mean()\n",
    "            \n",
    "            # Factor 3: Distance to other clusters (uniqueness)\n",
    "            distances = np.linalg.norm(centers[i] - centers, axis=1)\n",
    "            distances[i] = 0  # Remove self-distance\n",
    "            uniqueness_score = distances.mean()\n",
    "            \n",
    "            # Combine scores\n",
    "            importance[i] = 0.4 * size_score + 0.3 * variance_score + 0.3 * uniqueness_score\n",
    "        \n",
    "        # Normalize\n",
    "        importance = importance / (importance.sum() + 1e-8)\n",
    "        \n",
    "        return importance\n",
    "    \n",
    "    def _proportional_sample(self, slide_path, tissue_mask, importance, \n",
    "                            existing_coords, n_samples, patch_size):\n",
    "        \"\"\"Sample proportionally to cluster importance\"\"\"\n",
    "        # For simplicity, just do additional random sampling\n",
    "        # In full implementation, would sample based on cluster regions\n",
    "        return self._uniform_sample(slide_path, tissue_mask, n_samples, patch_size)\n",
    "\n",
    "# ============================================================\n",
    "# MULTI-SEED STABILITY ANALYZER (NOVELTY 3)\n",
    "# ============================================================\n",
    "class StabilityAnalyzer:\n",
    "    \"\"\"\n",
    "    Uncertainty-aware feature extraction:\n",
    "    - Multi-seed sampling\n",
    "    - Per-slide confidence intervals\n",
    "    - Unstable slide detection\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seeds=MULTI_SEED_SAMPLING):\n",
    "        self.seeds = seeds\n",
    "    \n",
    "    def compute_stability(self, embeddings_list):\n",
    "        \"\"\"\n",
    "        Compute stability across multiple samplings\n",
    "        \n",
    "        Args:\n",
    "            embeddings_list: List of slide embeddings from different seeds\n",
    "        \n",
    "        Returns:\n",
    "            stability_score: Mean cosine similarity\n",
    "            confidence_score: 1 / (1 + variance)\n",
    "        \"\"\"\n",
    "        if len(embeddings_list) < 2:\n",
    "            return 1.0, 1.0\n",
    "        \n",
    "        # Compute pairwise cosine similarities\n",
    "        similarities = []\n",
    "        for i in range(len(embeddings_list)):\n",
    "            for j in range(i+1, len(embeddings_list)):\n",
    "                emb1 = embeddings_list[i]\n",
    "                emb2 = embeddings_list[j]\n",
    "                \n",
    "                # Cosine similarity\n",
    "                sim = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2) + 1e-8)\n",
    "                similarities.append(sim)\n",
    "        \n",
    "        stability_score = np.mean(similarities)\n",
    "        variance = np.var(similarities)\n",
    "        confidence_score = 1.0 / (1.0 + variance)\n",
    "        \n",
    "        return stability_score, confidence_score\n",
    "    \n",
    "    def flag_unstable_slides(self, stability_scores, threshold=0.85):\n",
    "        \"\"\"Identify slides with low stability\"\"\"\n",
    "        unstable = []\n",
    "        for slide_id, score in stability_scores.items():\n",
    "            if score < threshold:\n",
    "                unstable.append((slide_id, score))\n",
    "        \n",
    "        return sorted(unstable, key=lambda x: x[1])\n",
    "\n",
    "# ============================================================\n",
    "# HETEROGENEITY QUANTIFICATION (NOVELTY 4)\n",
    "# ============================================================\n",
    "class HeterogeneityAnalyzer:\n",
    "    \"\"\"\n",
    "    Quantify slide-level heterogeneity:\n",
    "    - Intra-slide diversity\n",
    "    - Cluster count estimation\n",
    "    - Correlation with clinical metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_heterogeneity(self, patch_features):\n",
    "        \"\"\"\n",
    "        Compute heterogeneity score\n",
    "        \n",
    "        Args:\n",
    "            patch_features: (N_patches, feature_dim)\n",
    "        \n",
    "        Returns:\n",
    "            heterogeneity_score: Aggregated score\n",
    "            metrics: Dict of individual metrics\n",
    "        \"\"\"\n",
    "        if len(patch_features) < 10:\n",
    "            return 0.0, {}\n",
    "        \n",
    "        # Metric 1: Mean pairwise distance\n",
    "        distances = pdist(patch_features, metric='cosine')\n",
    "        mean_distance = np.mean(distances)\n",
    "        std_distance = np.std(distances)\n",
    "        \n",
    "        # Metric 2: Estimate number of clusters (elbow method)\n",
    "        inertias = []\n",
    "        k_range = range(2, min(10, len(patch_features)//10))\n",
    "        for k in k_range:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            kmeans.fit(patch_features)\n",
    "            inertias.append(kmeans.inertia_)\n",
    "        \n",
    "        # Estimate clusters using elbow\n",
    "        if len(inertias) >= 2:\n",
    "            diffs = np.diff(inertias)\n",
    "            elbow_k = np.argmin(diffs) + 2\n",
    "        else:\n",
    "            elbow_k = 2\n",
    "        \n",
    "        # Metric 3: Silhouette score\n",
    "        if elbow_k < len(patch_features):\n",
    "            kmeans = KMeans(n_clusters=elbow_k, random_state=42, n_init=10)\n",
    "            labels = kmeans.fit_predict(patch_features)\n",
    "            silhouette = silhouette_score(patch_features, labels, metric='cosine')\n",
    "        else:\n",
    "            silhouette = 0.0\n",
    "        \n",
    "        # Metric 4: Feature entropy\n",
    "        pca = PCA(n_components=min(50, patch_features.shape[1]))\n",
    "        pca.fit(patch_features)\n",
    "        variance_ratios = pca.explained_variance_ratio_\n",
    "        entropy = -np.sum(variance_ratios * np.log(variance_ratios + 1e-8))\n",
    "        \n",
    "        metrics = {\n",
    "            'mean_distance': float(mean_distance),\n",
    "            'std_distance': float(std_distance),\n",
    "            'estimated_clusters': int(elbow_k),\n",
    "            'silhouette': float(silhouette),\n",
    "            'feature_entropy': float(entropy)\n",
    "        }\n",
    "        \n",
    "        # Aggregate heterogeneity score\n",
    "        # Higher distance, more clusters, lower silhouette = higher heterogeneity\n",
    "        heterogeneity_score = (\n",
    "            0.3 * mean_distance +\n",
    "            0.2 * (elbow_k / 10.0) +\n",
    "            0.3 * (1.0 - silhouette) +\n",
    "            0.2 * (entropy / 4.0)\n",
    "        )\n",
    "        \n",
    "        return float(heterogeneity_score), metrics\n",
    "\n",
    "# ============================================================\n",
    "# NUCLEUS SEGMENTATION (Enhanced)\n",
    "# ============================================================\n",
    "class NucleusSegmenter:\n",
    "    def extract_hematoxylin(self, rgb):\n",
    "        rgb = np.clip(rgb, 1, 255)/255.0\n",
    "        od = -np.log(rgb + 1e-6)\n",
    "        h = od[:, :, 2]\n",
    "        return ((h - h.min()) / (h.max() - h.min() + 1e-8) * 255).astype(np.uint8)\n",
    "\n",
    "    def segment(self, rgb):\n",
    "        h = self.extract_hematoxylin(rgb)\n",
    "        h = gaussian(h, 1.0, preserve_range=True).astype(np.uint8)\n",
    "        bin_ = cv2.adaptiveThreshold(h, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                     cv2.THRESH_BINARY, 11, 2)\n",
    "        bin_ = remove_small_objects(bin_.astype(bool), 20)\n",
    "        bin_ = binary_dilation(bin_, disk(1))\n",
    "        bin_ = binary_erosion(bin_, disk(1))\n",
    "        dist = distance_transform_edt(bin_)\n",
    "        maxima = maximum_filter(dist, footprint=np.ones((5, 5)))\n",
    "        markers = label(dist == maxima)\n",
    "        return watershed(-dist, markers, mask=bin_)\n",
    "\n",
    "    def features(self, labels, rgb):\n",
    "        props = regionprops(labels)\n",
    "        if not props:\n",
    "            return None\n",
    "\n",
    "        valid_props = [p for p in props if 80 < p.area < 8000]\n",
    "        if not valid_props:\n",
    "            return None\n",
    "\n",
    "        areas = np.array([p.area for p in valid_props])\n",
    "        perimeters = np.array([p.perimeter for p in valid_props])\n",
    "        circularities = 4 * np.pi * areas / (perimeters ** 2 + 1e-8)\n",
    "        eccentricities = np.array([p.eccentricity for p in valid_props])\n",
    "        solidities = np.array([p.solidity for p in valid_props])\n",
    "\n",
    "        feats = {\n",
    "            \"nuc_count\": len(valid_props),\n",
    "            \"nuc_area_mean\": areas.mean(),\n",
    "            \"nuc_area_std\": areas.std(),\n",
    "            \"nuc_area_p25\": np.percentile(areas, 25),\n",
    "            \"nuc_area_p75\": np.percentile(areas, 75),\n",
    "            \"nuc_perimeter_mean\": perimeters.mean(),\n",
    "            \"nuc_perimeter_std\": perimeters.std(),\n",
    "            \"nuc_circularity_mean\": circularities.mean(),\n",
    "            \"nuc_circularity_std\": circularities.std(),\n",
    "            \"nuc_eccentricity_mean\": eccentricities.mean(),\n",
    "            \"nuc_solidity_mean\": solidities.mean(),\n",
    "        }\n",
    "\n",
    "        return feats\n",
    "\n",
    "# ============================================================\n",
    "# TEXTURE & ARCHITECTURE FEATURES\n",
    "# ============================================================\n",
    "class TextureFeatures:\n",
    "    @staticmethod\n",
    "    def extract(rgb):\n",
    "        g = rgb2gray(rgb)\n",
    "\n",
    "        arch = {\n",
    "            \"arch_entropy\": stats.entropy(np.histogram(g, bins=32)[0] + 1e-8),\n",
    "            \"arch_contrast\": np.std(g),\n",
    "        }\n",
    "\n",
    "        hsv = rgb2hsv(rgb)\n",
    "        color = {\n",
    "            \"color_h_mean\": hsv[:,:,0].mean(),\n",
    "            \"color_s_mean\": hsv[:,:,1].mean(),\n",
    "            \"color_v_mean\": hsv[:,:,2].mean(),\n",
    "        }\n",
    "\n",
    "        return {**arch, **color}\n",
    "\n",
    "# ============================================================\n",
    "# CTRANSPATH EXTRACTOR\n",
    "# ============================================================\n",
    "class CTransPathExtractor:\n",
    "    def __init__(self, weights_path=CTRANSPATH_WEIGHTS):\n",
    "        log_msg(\"  Loading CTransPath model...\")\n",
    "\n",
    "        try:\n",
    "            if os.path.exists(weights_path):\n",
    "                checkpoint = torch.load(weights_path, map_location='cpu')\n",
    "                if 'model' in checkpoint:\n",
    "                    state_dict = checkpoint['model']\n",
    "                elif 'state_dict' in checkpoint:\n",
    "                    state_dict = checkpoint['state_dict']\n",
    "                else:\n",
    "                    state_dict = checkpoint\n",
    "\n",
    "                self.model = timm.create_model(\n",
    "                    \"swin_tiny_patch4_window7_224\",\n",
    "                    pretrained=False,\n",
    "                    num_classes=0,\n",
    "                    global_pool='avg'\n",
    "                )\n",
    "                self.model.load_state_dict(state_dict, strict=False)\n",
    "                log_msg(\"    ✅ CTransPath checkpoint loaded\")\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Weights not found: {weights_path}\")\n",
    "        except Exception as e:\n",
    "            log_msg(f\"    ⚠️ Failed to load checkpoint: {e}\")\n",
    "            log_msg(\"    ✅ Using pretrained Swin-Tiny fallback\")\n",
    "            self.model = timm.create_model(\n",
    "                \"swin_tiny_patch4_window7_224\",\n",
    "                pretrained=True,\n",
    "                num_classes=0,\n",
    "                global_pool='avg'\n",
    "            )\n",
    "\n",
    "        self.model = self.model.to(DEVICE).eval()\n",
    "\n",
    "        self.tf = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def extract(self, tiles):\n",
    "        feats = []\n",
    "        for t in tiles:\n",
    "            try:\n",
    "                x = self.tf(Image.fromarray(t)).unsqueeze(0).to(DEVICE)\n",
    "                with torch.no_grad():\n",
    "                    f = self.model(x).squeeze().cpu().numpy()\n",
    "                    if len(f.shape) == 0:\n",
    "                        f = np.array([f])\n",
    "                    feats.append(f)\n",
    "            except Exception as e:\n",
    "                log_msg(f\"    ⚠️ CTransPath extraction failed: {e}\")\n",
    "                continue\n",
    "\n",
    "        if not feats:\n",
    "            return None\n",
    "\n",
    "        feats = np.array(feats)\n",
    "        return feats\n",
    "\n",
    "# ============================================================\n",
    "# ENHANCED EVALUATION METRICS\n",
    "# ============================================================\n",
    "class EnhancedMetrics:\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation metrics:\n",
    "    - Stability (multi-seed)\n",
    "    - Redundancy (PCA effective dimension)\n",
    "    - Separability (silhouette)\n",
    "    - Robustness (perturbation tests)\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_redundancy(features):\n",
    "        \"\"\"\n",
    "        Redundancy via PCA effective dimension\n",
    "        \n",
    "        Returns:\n",
    "            effective_dim: # components for 95% variance\n",
    "            redundancy_ratio: % of redundant dimensions\n",
    "        \"\"\"\n",
    "        if len(features) < 2:\n",
    "            return 0, 0.0\n",
    "        \n",
    "        pca = PCA()\n",
    "        pca.fit(features)\n",
    "        \n",
    "        cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "        effective_dim = np.argmax(cumsum >= 0.95) + 1\n",
    "        \n",
    "        total_dim = features.shape[1]\n",
    "        redundancy_ratio = 1.0 - (effective_dim / total_dim)\n",
    "        \n",
    "        return effective_dim, redundancy_ratio\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_separability(features, labels):\n",
    "        \"\"\"\n",
    "        Separability using silhouette score\n",
    "        \n",
    "        Args:\n",
    "            features: (N, D) feature matrix\n",
    "            labels: (N,) label array\n",
    "        \n",
    "        Returns:\n",
    "            silhouette: Silhouette score [-1, 1]\n",
    "        \"\"\"\n",
    "        if len(np.unique(labels)) < 2 or len(features) < 10:\n",
    "            return 0.0\n",
    "        \n",
    "        return silhouette_score(features, labels, metric='cosine')\n",
    "\n",
    "# ============================================================\n",
    "# MAIN PIPELINE\n",
    "# ============================================================\n",
    "def main():\n",
    "    files = [f for f in os.listdir(SVS_DIR) if f.lower().endswith('.svs')]\n",
    "\n",
    "    if len(files) == 0:\n",
    "        log_msg(\"❌ No SVS files found!\")\n",
    "        return\n",
    "\n",
    "    np.random.shuffle(files)\n",
    "\n",
    "    # Initialize modules\n",
    "    patch_qc = AdvancedPatchQC()\n",
    "    adaptive_sampler = AdaptiveSampler(n_initial=200, n_final=TARGET_PATCHES, n_clusters=5)\n",
    "    stability_analyzer = StabilityAnalyzer()\n",
    "    heterogeneity_analyzer = HeterogeneityAnalyzer()\n",
    "    nuc = NucleusSegmenter()\n",
    "    tex = TextureFeatures()\n",
    "    ctrans = CTransPathExtractor(CTRANSPATH_WEIGHTS)\n",
    "    metrics = EnhancedMetrics()\n",
    "\n",
    "    log_msg(\"\\n\" + \"=\"*80)\n",
    "    log_msg(\"STEP 1: ENHANCED FEATURE EXTRACTION\")\n",
    "    log_msg(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    all_rows = []\n",
    "    qc_rows = []\n",
    "    stability_scores = {}\n",
    "    heterogeneity_scores = {}\n",
    "\n",
    "    for i, fn in enumerate(files[:10], 1):  # Process first 10 for demo\n",
    "        try:\n",
    "            log_msg(f\"[{i}/{min(10, len(files))}] {fn}\")\n",
    "            \n",
    "            slide_path = os.path.join(SVS_DIR, fn)\n",
    "            sl = openslide.OpenSlide(slide_path)\n",
    "            lv = sl.get_best_level_for_downsample(1)\n",
    "            ds = sl.level_downsamples[lv]\n",
    "            w, h = sl.level_dimensions[lv]\n",
    "            \n",
    "            # Generate tissue mask AT THUMBNAIL RESOLUTION (memory efficient)\n",
    "            # Use thumbnail size, not full resolution\n",
    "            thumb_w, thumb_h = w // 32, h // 32  # 32x downsample\n",
    "            thumbnail = sl.get_thumbnail((thumb_w, thumb_h))\n",
    "            thumbnail_arr = np.array(thumbnail)\n",
    "            hsv = rgb2hsv(thumbnail_arr)\n",
    "            \n",
    "            thresh = threshold_otsu(hsv[:,:,1])\n",
    "            tissue_mask = hsv[:,:,1] > thresh\n",
    "            tissue_mask = remove_small_objects(tissue_mask, min_size=50)\n",
    "            \n",
    "            # tissue_mask is now (thumb_h, thumb_w) - much smaller!\n",
    "            # The adaptive sampler will handle scaling internally\n",
    "            \n",
    "            sl.close()\n",
    "            \n",
    "            # MULTI-SEED SAMPLING for stability\n",
    "            all_seed_embeddings = []\n",
    "            \n",
    "            for seed_idx, seed in enumerate(MULTI_SEED_SAMPLING):\n",
    "                np.random.seed(seed)\n",
    "                \n",
    "                log_msg(f\"  Seed {seed_idx+1}/{len(MULTI_SEED_SAMPLING)}: {seed}\")\n",
    "                \n",
    "                # Adaptive sampling\n",
    "                tiles, coords = adaptive_sampler.sample(\n",
    "                    slide_path, tissue_mask, PATCH_SIZE\n",
    "                )\n",
    "                \n",
    "                if len(tiles) < 50:\n",
    "                    log_msg(f\"  ❌ Insufficient tiles for seed {seed}\")\n",
    "                    continue\n",
    "                \n",
    "                # Extract CTransPath features\n",
    "                patch_features = ctrans.extract(tiles)\n",
    "                \n",
    "                if patch_features is None:\n",
    "                    continue\n",
    "                \n",
    "                # Aggregate to slide-level\n",
    "                slide_embedding = patch_features.mean(axis=0)\n",
    "                all_seed_embeddings.append(slide_embedding)\n",
    "            \n",
    "            if len(all_seed_embeddings) < 2:\n",
    "                log_msg(f\"  ❌ Failed to extract features across seeds\")\n",
    "                qc_rows.append({'slide': fn, 'status': 'fail', 'reason': 'multi-seed failure'})\n",
    "                continue\n",
    "            \n",
    "            # Compute stability\n",
    "            stability, confidence = stability_analyzer.compute_stability(all_seed_embeddings)\n",
    "            stability_scores[fn] = stability\n",
    "            \n",
    "            log_msg(f\"  ✅ Stability: {stability:.4f}, Confidence: {confidence:.4f}\")\n",
    "            \n",
    "            # Use first seed's features for full analysis\n",
    "            np.random.seed(MULTI_SEED_SAMPLING[0])\n",
    "            tiles, coords = adaptive_sampler.sample(slide_path, tissue_mask, PATCH_SIZE)\n",
    "            \n",
    "            # Extract all features\n",
    "            row = {\"slide\": fn, \"stability\": stability, \"confidence\": confidence}\n",
    "            \n",
    "            # Nucleus morphology\n",
    "            nuc_feats = []\n",
    "            for t in tiles[:100]:  # Subsample for speed\n",
    "                lbl = nuc.segment(t)\n",
    "                f = nuc.features(lbl, t)\n",
    "                if f:\n",
    "                    nuc_feats.append(f)\n",
    "            \n",
    "            if nuc_feats:\n",
    "                df = pd.DataFrame(nuc_feats)\n",
    "                for c in df.columns:\n",
    "                    row[f\"{c}_mean\"] = df[c].mean()\n",
    "                    row[f\"{c}_std\"] = df[c].std()\n",
    "            \n",
    "            # Texture features\n",
    "            tex_feats = [tex.extract(t) for t in tiles[:100]]\n",
    "            df = pd.DataFrame(tex_feats)\n",
    "            for c in df.columns:\n",
    "                row[f\"{c}_mean\"] = df[c].mean()\n",
    "                row[f\"{c}_std\"] = df[c].std()\n",
    "            \n",
    "            # CTransPath features\n",
    "            patch_features = ctrans.extract(tiles)\n",
    "            if patch_features is not None:\n",
    "                # Compute heterogeneity\n",
    "                heterogeneity, het_metrics = heterogeneity_analyzer.compute_heterogeneity(patch_features)\n",
    "                heterogeneity_scores[fn] = heterogeneity\n",
    "                row['heterogeneity'] = heterogeneity\n",
    "                for k, v in het_metrics.items():\n",
    "                    row[f'het_{k}'] = v\n",
    "                \n",
    "                # Aggregate features\n",
    "                slide_features = patch_features.mean(axis=0)\n",
    "                for j, x in enumerate(slide_features):\n",
    "                    row[f\"ctrans_mean_{j}\"] = float(x)\n",
    "                \n",
    "                # Compute redundancy\n",
    "                eff_dim, redundancy = metrics.compute_redundancy(patch_features)\n",
    "                row['pca_effective_dim'] = eff_dim\n",
    "                row['redundancy_ratio'] = redundancy\n",
    "            \n",
    "            all_rows.append(row)\n",
    "            qc_rows.append({'slide': fn, 'status': 'ok', 'tiles': len(tiles), \n",
    "                           'stability': stability, 'heterogeneity': heterogeneity})\n",
    "            \n",
    "            log_msg(f\"  ✅ Complete | Heterogeneity: {heterogeneity:.3f} | Redundancy: {redundancy:.3f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            log_msg(f\"  ❌ Error: {e}\")\n",
    "            traceback.print_exc()\n",
    "            qc_rows.append({'slide': fn, 'status': 'fail', 'reason': str(e)})\n",
    "            continue\n",
    "\n",
    "    # Save results\n",
    "    log_msg(\"\\n\" + \"=\"*80)\n",
    "    log_msg(\"SAVING ENHANCED RESULTS\")\n",
    "    log_msg(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    if all_rows:\n",
    "        df = pd.DataFrame(all_rows)\n",
    "        df.to_csv(f\"{OUTPUT_DIR}/enhanced_features.csv\", index=False)\n",
    "        log_msg(f\"✅ Features saved: {len(df)} slides × {len(df.columns)} features\")\n",
    "        \n",
    "        # Save stability scores\n",
    "        with open(f\"{OUTPUT_DIR}/stability_analysis.json\", 'w') as f:\n",
    "            json.dump({\n",
    "                'stability_scores': stability_scores,\n",
    "                'heterogeneity_scores': heterogeneity_scores,\n",
    "                'unstable_slides': stability_analyzer.flag_unstable_slides(stability_scores),\n",
    "                'mean_stability': float(np.mean(list(stability_scores.values()))),\n",
    "                'std_stability': float(np.std(list(stability_scores.values())))\n",
    "            }, f, indent=2)\n",
    "        log_msg(f\"✅ Stability analysis saved\")\n",
    "        \n",
    "        # Generate evaluation figures\n",
    "        generate_evaluation_figures(df, stability_scores, heterogeneity_scores)\n",
    "    \n",
    "    # Save QC\n",
    "    qc_df = pd.DataFrame(qc_rows)\n",
    "    qc_df.to_csv(f\"{OUTPUT_DIR}/qc_enhanced.csv\", index=False)\n",
    "    log_msg(f\"✅ QC saved: {OUTPUT_DIR}/qc_enhanced.csv\")\n",
    "    \n",
    "    log_msg(\"\\n\" + \"=\"*80)\n",
    "    log_msg(\"✅ ENHANCED PIPELINE COMPLETE\")\n",
    "    log_msg(f\"✅ Output directory: {OUTPUT_DIR}\")\n",
    "    log_msg(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# EVALUATION FIGURE GENERATION\n",
    "# ============================================================\n",
    "def generate_evaluation_figures(df, stability_scores, heterogeneity_scores):\n",
    "    \"\"\"Generate comprehensive evaluation figures\"\"\"\n",
    "    \n",
    "    log_msg(\"\\nGenerating evaluation figures...\")\n",
    "    \n",
    "    # Figure 1: Stability Distribution\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Panel A: Stability distribution\n",
    "    ax = axes[0, 0]\n",
    "    stab_values = list(stability_scores.values())\n",
    "    ax.hist(stab_values, bins=20, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(np.mean(stab_values), color='red', linestyle='--', linewidth=2,\n",
    "               label=f'Mean: {np.mean(stab_values):.3f}')\n",
    "    ax.set_xlabel('Stability Score', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('A. Multi-Seed Stability Distribution', fontsize=12, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Panel B: Heterogeneity distribution\n",
    "    ax = axes[0, 1]\n",
    "    het_values = list(heterogeneity_scores.values())\n",
    "    ax.hist(het_values, bins=20, color='coral', alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(np.mean(het_values), color='darkred', linestyle='--', linewidth=2,\n",
    "               label=f'Mean: {np.mean(het_values):.3f}')\n",
    "    ax.set_xlabel('Heterogeneity Score', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('B. Slide-Level Heterogeneity', fontsize=12, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Panel C: Stability vs Heterogeneity\n",
    "    ax = axes[1, 0]\n",
    "    common_slides = set(stability_scores.keys()) & set(heterogeneity_scores.keys())\n",
    "    stab = [stability_scores[s] for s in common_slides]\n",
    "    het = [heterogeneity_scores[s] for s in common_slides]\n",
    "    ax.scatter(het, stab, s=100, alpha=0.6, c='purple', edgecolors='black')\n",
    "    \n",
    "    # Correlation\n",
    "    if len(stab) > 2:\n",
    "        corr = np.corrcoef(het, stab)[0, 1]\n",
    "        ax.text(0.05, 0.95, f'Correlation: {corr:.3f}', \n",
    "               transform=ax.transAxes, fontsize=10, va='top',\n",
    "               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlabel('Heterogeneity Score', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Stability Score', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('C. Stability vs Heterogeneity', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Panel D: PCA Effective Dimension\n",
    "    ax = axes[1, 1]\n",
    "    if 'pca_effective_dim' in df.columns:\n",
    "        dims = df['pca_effective_dim'].dropna()\n",
    "        ax.hist(dims, bins=15, color='gold', alpha=0.7, edgecolor='black')\n",
    "        ax.axvline(dims.mean(), color='darkgreen', linestyle='--', linewidth=2,\n",
    "                   label=f'Mean: {dims.mean():.1f}')\n",
    "        ax.set_xlabel('Effective Dimensions', fontsize=11, fontweight='bold')\n",
    "        ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "        ax.set_title('D. Feature Redundancy (PCA)', fontsize=12, fontweight='bold')\n",
    "        ax.legend()\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'No PCA data', ha='center', va='center',\n",
    "               fontsize=14, transform=ax.transAxes)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{FIGURES_DIR}/01_enhanced_metrics.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    log_msg(f\"  ✅ Saved: 01_enhanced_metrics.png\")\n",
    "    \n",
    "    # Figure 2: Confidence Analysis\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    if 'confidence' in df.columns:\n",
    "        conf_values = df['confidence'].dropna()\n",
    "        colors = ['green' if c > 0.9 else 'orange' if c > 0.8 else 'red' for c in conf_values]\n",
    "        \n",
    "        ax.bar(range(len(conf_values)), conf_values, color=colors, alpha=0.7, edgecolor='black')\n",
    "        ax.axhline(0.9, color='green', linestyle='--', linewidth=2, alpha=0.5, label='High confidence')\n",
    "        ax.axhline(0.8, color='orange', linestyle='--', linewidth=2, alpha=0.5, label='Medium confidence')\n",
    "        \n",
    "        ax.set_xlabel('Slide Index', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Confidence Score', fontsize=12, fontweight='bold')\n",
    "        ax.set_title('Per-Slide Confidence Scores (Uncertainty Quantification)', \n",
    "                    fontsize=13, fontweight='bold')\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{FIGURES_DIR}/02_confidence_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        log_msg(f\"  ✅ Saved: 02_confidence_analysis.png\")\n",
    "    \n",
    "    log_msg(\"✅ Evaluation figures complete\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aba52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\paper\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "WSI-FEATUREQC: COMPLETE FEATURE EXTRACTION & EVALUATION FRAMEWORK\n",
      "================================================================================\n",
      "Device: cpu\n",
      "Multi-seed sampling: 5 seeds\n",
      "Output: WSI_FEATUREQC_COMPLETE\n",
      "\n",
      "[2026-01-19 14:11:58] Calibration slides: 11\n",
      "[2026-01-19 14:11:58] Processing slides: 10\n",
      "[2026-01-19 14:11:58] \n",
      "================================================================================\n",
      "[2026-01-19 14:11:58] STEP 1: PARAMETER OPTIMIZATION\n",
      "[2026-01-19 14:11:58] ================================================================================\n",
      "\n",
      "[2026-01-19 14:11:58] \n",
      "================================================================================\n",
      "[2026-01-19 14:11:58] RUNNING FULL PARAMETER OPTIMIZATION\n",
      "[2026-01-19 14:11:58] ================================================================================\n",
      "\n",
      "[2026-01-19 14:11:58] Optimizing tile count using Elbow method...\n",
      "[2026-01-19 14:12:41]   ✅ Optimal tile count: 500\n",
      "[2026-01-19 14:12:41] Optimizing blur threshold using Youden's J...\n",
      "[2026-01-19 14:12:55]   ✅ Blur threshold: 0.23\n",
      "[2026-01-19 14:12:55] Optimizing tissue threshold using multi-method consensus...\n",
      "[2026-01-19 14:13:06]   ✅ Tissue threshold: 0.300\n",
      "[2026-01-19 14:13:06] Computing bootstrap stability...\n",
      "[2026-01-19 14:13:12]   ✅ Bootstrap: 0.15 ± 0.01\n",
      "[2026-01-19 14:13:12] Computing stain normalization statistics...\n",
      "[2026-01-19 14:13:20]   ✅ Stain stats: RGB means = [0.779 0.665 0.877]\n",
      "[2026-01-19 14:13:20] ✅ Optimization results saved\n",
      "[2026-01-19 14:13:20] \n",
      "✅ Optimization complete\n",
      "[2026-01-19 14:13:20] \n",
      "================================================================================\n",
      "[2026-01-19 14:13:20] INITIALIZING ENCODERS\n",
      "[2026-01-19 14:13:20] ================================================================================\n",
      "\n",
      "[2026-01-19 14:13:20]   Loading ResNet-50 (ImageNet)...\n",
      "[2026-01-19 14:13:21]     ✅ ResNet-50 loaded\n",
      "[2026-01-19 14:13:21]   Loading CTransPath...\n",
      "[2026-01-19 14:13:22]     ✅ CTransPath loaded from checkpoint\n",
      "[2026-01-19 14:13:22] \n",
      "✅ Initialized 2 encoders\n",
      "[2026-01-19 14:13:22] \n",
      "================================================================================\n",
      "[2026-01-19 14:13:22] STEP 2: FEATURE EXTRACTION\n",
      "[2026-01-19 14:13:22] ================================================================================\n",
      "\n",
      "[2026-01-19 14:13:22] \n",
      "Encoder: resnet50\n",
      "[2026-01-19 14:13:22]   Processing YG_P8W7SBCME4VH_wsi with resnet50...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# WSI-FEATUREQC: COMPLETE FEATURE EXTRACTION & EVALUATION FRAMEWORK\n",
    "# Based on: \"A Modular Framework for Robust Feature Extraction from WSI\"\n",
    "# \n",
    "# Components:\n",
    "# 1. Data-driven parameter optimization (5 methods)\n",
    "# 2. Multi-seed stability analysis\n",
    "# 3. Advanced patch quality control\n",
    "# 4. Multiple encoder support (ResNet50, DINO, CTransPath)\n",
    "# 5. Comprehensive evaluation metrics (Stability, Redundancy, Separability, Robustness)\n",
    "# 6. Framework comparison (vs CLAM, Naive CNN, Radiomics)\n",
    "# 7. Complete visualization suite (20+ figures)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openslide\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from skimage.filters import threshold_otsu, laplace, gaussian\n",
    "from skimage.morphology import (remove_small_objects, binary_dilation, \n",
    "                                 binary_erosion, disk, binary_closing)\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.color import rgb2hsv, rgb2gray\n",
    "from skimage.measure import regionprops, label, shannon_entropy\n",
    "from scipy.ndimage import distance_transform_edt, maximum_filter\n",
    "from scipy.spatial.distance import pdist, squareform, cosine\n",
    "from scipy import stats\n",
    "from scipy.stats import wilcoxon\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import timm\n",
    "import traceback\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.cluster import KMeans\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===============================\n",
    "# GLOBAL CONFIG\n",
    "# ===============================\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Paths\n",
    "SVS_DIR = r\"C:\\Users\\Shahinur\\Downloads\\PKG_Dataset\\PKG - Brain-Mets-Lung-MRI-Path-Segs_histopathology images\\data\"\n",
    "CTRANSPATH_WEIGHTS = r\"D:\\paper\\weights\\ctranspath.pth\"\n",
    "OUTPUT_DIR = \"WSI_FEATUREQC_COMPLETE\"\n",
    "FIGURES_DIR = f\"{OUTPUT_DIR}/figures\"\n",
    "FEATURES_DIR = f\"{OUTPUT_DIR}/features\"\n",
    "\n",
    "# Create directories\n",
    "for d in [OUTPUT_DIR, FIGURES_DIR, FEATURES_DIR]:\n",
    "    Path(d).mkdir(exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Multi-seed sampling for stability\n",
    "RANDOM_SEEDS = [42, 123, 456, 789, 1011]\n",
    "\n",
    "# Plotting\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"WSI-FEATUREQC: COMPLETE FEATURE EXTRACTION & EVALUATION FRAMEWORK\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Multi-seed sampling: {len(RANDOM_SEEDS)} seeds\")\n",
    "print(f\"Output: {OUTPUT_DIR}\\n\")\n",
    "\n",
    "def log_msg(msg):\n",
    "    \"\"\"Logging with timestamp\"\"\"\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"[{timestamp}] {msg}\")\n",
    "    try:\n",
    "        with open(f\"{OUTPUT_DIR}/pipeline.log\", 'a') as f:\n",
    "            f.write(f\"[{timestamp}] {msg}\\n\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PART 1: DATA-DRIVEN PARAMETER OPTIMIZER\n",
    "# ============================================================\n",
    "\n",
    "class MultiMethodOptimizer:\n",
    "    \"\"\"\n",
    "    Optimize preprocessing parameters using 5 complementary methods:\n",
    "    1. Elbow method for tile count\n",
    "    2. Youden's J for blur threshold  \n",
    "    3. Multi-method consensus for tissue threshold\n",
    "    4. Bootstrap for parameter stability\n",
    "    5. Entropy for stain normalization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, calibration_slides, n_samples=300):\n",
    "        self.slides = calibration_slides\n",
    "        self.n_samples = n_samples\n",
    "        self.results = {}\n",
    "        self.calibration_data = {\n",
    "            'tile_counts': [],\n",
    "            'tile_variances': [],\n",
    "            'blur_scores': [],\n",
    "            'tissue_percentages': [],\n",
    "            'bootstrap_samples': [],\n",
    "            'stain_means': [],\n",
    "            'stain_stds': []\n",
    "        }\n",
    "    \n",
    "    def _is_background(self, tile):\n",
    "        \"\"\"Check if tile is mostly background\"\"\"\n",
    "        return np.mean(tile) > 220\n",
    "    \n",
    "    def _compute_blur(self, tile):\n",
    "        \"\"\"Compute blur score (Laplacian variance + gradient)\"\"\"\n",
    "        gray = rgb2gray(tile)\n",
    "        lap_var = laplace(gray).var()\n",
    "        grad = np.sqrt(np.gradient(gray)[0]**2 + np.gradient(gray)[1]**2).mean()\n",
    "        return lap_var + (grad * 10 if lap_var < 10 else 0)\n",
    "    \n",
    "    def _compute_tissue_mask(self, tile):\n",
    "        \"\"\"Generate tissue mask using Otsu thresholding\"\"\"\n",
    "        gray = np.mean(tile, axis=2)\n",
    "        threshold = threshold_otsu(gray) if gray.std() > 1 else 200\n",
    "        mask = gray < threshold\n",
    "        mask = remove_small_objects(mask, min_size=500)\n",
    "        mask = binary_dilation(mask, disk(3))\n",
    "        return mask\n",
    "    \n",
    "    def optimize_tile_count(self, tile_size=224, max_tiles=250):\n",
    "        \"\"\"Method 1: Elbow method for optimal tile count\"\"\"\n",
    "        log_msg(\"Optimizing tile count using Elbow method...\")\n",
    "        \n",
    "        tile_counts, variances = [], []\n",
    "        \n",
    "        for slide_path in self.slides[:3]:  # Use first 3 slides\n",
    "            try:\n",
    "                slide = openslide.OpenSlide(slide_path)\n",
    "                level = slide.get_best_level_for_downsample(1)\n",
    "                downsample = slide.level_downsamples[level]\n",
    "                width, height = slide.level_dimensions[level]\n",
    "                \n",
    "                tiles = []\n",
    "                for y in range(0, height - tile_size, tile_size):\n",
    "                    for x in range(0, width - tile_size, tile_size):\n",
    "                        if len(tiles) >= max_tiles:\n",
    "                            break\n",
    "                        \n",
    "                        tile = np.array(slide.read_region(\n",
    "                            (int(x*downsample), int(y*downsample)),\n",
    "                            level,\n",
    "                            (tile_size, tile_size)\n",
    "                        ).convert(\"RGB\"))\n",
    "                        \n",
    "                        if not self._is_background(tile):\n",
    "                            mask = self._compute_tissue_mask(tile)\n",
    "                            if mask.sum() / mask.size >= 0.1:\n",
    "                                tiles.append(rgb2gray(tile).flatten())\n",
    "                    \n",
    "                    if len(tiles) >= max_tiles:\n",
    "                        break\n",
    "                \n",
    "                slide.close()\n",
    "                \n",
    "                if len(tiles) < 50:\n",
    "                    continue\n",
    "                \n",
    "                # Compute variance at different tile counts\n",
    "                tiles_array = np.array(tiles)\n",
    "                for n in range(25, min(max_tiles, len(tiles))+1, 25):\n",
    "                    variance = np.var(np.mean(tiles_array[:n], axis=0))\n",
    "                    variances.append(variance)\n",
    "                    tile_counts.append(n)\n",
    "                \n",
    "            except Exception as e:\n",
    "                log_msg(f\"  Warning: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if len(tile_counts) < 3:\n",
    "            log_msg(\"  Insufficient data, using default: 1000\")\n",
    "            return 1000\n",
    "        \n",
    "        # Store calibration data\n",
    "        self.calibration_data['tile_counts'] = tile_counts\n",
    "        self.calibration_data['tile_variances'] = variances\n",
    "        \n",
    "        # Find elbow using second derivative\n",
    "        tile_counts = np.array(tile_counts)\n",
    "        variances = np.array(variances)\n",
    "        second_deriv = np.gradient(np.gradient(variances))\n",
    "        optimal_idx = np.argmin(np.abs(second_deriv))\n",
    "        optimal = int(tile_counts[optimal_idx])\n",
    "        optimal = max(500, min(optimal * 4, 2000))  # Scale to realistic range\n",
    "        \n",
    "        self.results['tile_count'] = {\n",
    "            'optimal': optimal,\n",
    "            'method': 'elbow',\n",
    "            'elbow_point': int(tile_counts[optimal_idx])\n",
    "        }\n",
    "        \n",
    "        log_msg(f\"  ✅ Optimal tile count: {optimal}\")\n",
    "        return optimal\n",
    "    \n",
    "    def optimize_blur_threshold(self, tile_size=224):\n",
    "        \"\"\"Method 2: Youden's J for blur threshold\"\"\"\n",
    "        log_msg(\"Optimizing blur threshold using Youden's J...\")\n",
    "        \n",
    "        blur_scores = []\n",
    "        tissue_ratios = []\n",
    "        \n",
    "        for slide_path in self.slides[:4]:\n",
    "            try:\n",
    "                slide = openslide.OpenSlide(slide_path)\n",
    "                level = slide.get_best_level_for_downsample(1)\n",
    "                downsample = slide.level_downsamples[level]\n",
    "                width, height = slide.level_dimensions[level]\n",
    "                \n",
    "                for y in range(0, height - tile_size, tile_size):\n",
    "                    for x in range(0, width - tile_size, tile_size):\n",
    "                        if len(blur_scores) >= 500:\n",
    "                            break\n",
    "                        \n",
    "                        tile = np.array(slide.read_region(\n",
    "                            (int(x*downsample), int(y*downsample)),\n",
    "                            level,\n",
    "                            (tile_size, tile_size)\n",
    "                        ).convert(\"RGB\"))\n",
    "                        \n",
    "                        if not self._is_background(tile):\n",
    "                            blur_scores.append(self._compute_blur(tile))\n",
    "                            mask = self._compute_tissue_mask(tile)\n",
    "                            tissue_ratios.append(mask.sum() / mask.size)\n",
    "                    \n",
    "                    if len(blur_scores) >= 500:\n",
    "                        break\n",
    "                \n",
    "                slide.close()\n",
    "                \n",
    "            except Exception as e:\n",
    "                log_msg(f\"  Warning: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if len(blur_scores) < 100:\n",
    "            log_msg(\"  Insufficient data, using default: 50\")\n",
    "            return 50.0\n",
    "        \n",
    "        # Store calibration data\n",
    "        self.calibration_data['blur_scores'] = blur_scores\n",
    "        \n",
    "        # Youden's J optimization\n",
    "        blur_array = np.array(blur_scores)\n",
    "        tissue_array = np.array(tissue_ratios)\n",
    "        \n",
    "        # Define background and good tissue\n",
    "        background = tissue_array < 0.05\n",
    "        good_tissue = tissue_array >= 0.3\n",
    "        \n",
    "        if background.sum() < 10 or good_tissue.sum() < 10:\n",
    "            optimal = float(np.percentile(blur_array, 5))\n",
    "        else:\n",
    "            # Test thresholds\n",
    "            test_thresholds = np.percentile(blur_array, np.arange(1, 20))\n",
    "            j_scores = []\n",
    "            \n",
    "            for threshold in test_thresholds:\n",
    "                sensitivity = (blur_array[background] < threshold).sum() / (background.sum() + 1e-8)\n",
    "                specificity = (blur_array[good_tissue] >= threshold).sum() / (good_tissue.sum() + 1e-8)\n",
    "                j = sensitivity + specificity - 1\n",
    "                j_scores.append(j)\n",
    "            \n",
    "            optimal = float(test_thresholds[np.argmax(j_scores)])\n",
    "        \n",
    "        self.results['blur_threshold'] = {\n",
    "            'optimal': optimal,\n",
    "            'method': 'youden_j'\n",
    "        }\n",
    "        \n",
    "        log_msg(f\"  ✅ Blur threshold: {optimal:.2f}\")\n",
    "        return optimal\n",
    "    \n",
    "    def optimize_tissue_threshold(self, tile_size=224):\n",
    "        \"\"\"Method 3: Multi-method consensus for tissue threshold\"\"\"\n",
    "        log_msg(\"Optimizing tissue threshold using multi-method consensus...\")\n",
    "        \n",
    "        tissue_ratios = []\n",
    "        \n",
    "        for slide_path in self.slides[:5]:\n",
    "            try:\n",
    "                slide = openslide.OpenSlide(slide_path)\n",
    "                level = slide.get_best_level_for_downsample(1)\n",
    "                downsample = slide.level_downsamples[level]\n",
    "                width, height = slide.level_dimensions[level]\n",
    "                \n",
    "                for y in range(0, height - tile_size, tile_size):\n",
    "                    for x in range(0, width - tile_size, tile_size):\n",
    "                        if len(tissue_ratios) >= 600:\n",
    "                            break\n",
    "                        \n",
    "                        tile = np.array(slide.read_region(\n",
    "                            (int(x*downsample), int(y*downsample)),\n",
    "                            level,\n",
    "                            (tile_size, tile_size)\n",
    "                        ).convert(\"RGB\"))\n",
    "                        \n",
    "                        if not self._is_background(tile):\n",
    "                            mask = self._compute_tissue_mask(tile)\n",
    "                            tissue_ratios.append(mask.sum() / mask.size)\n",
    "                    \n",
    "                    if len(tissue_ratios) >= 600:\n",
    "                        break\n",
    "                \n",
    "                slide.close()\n",
    "                \n",
    "            except Exception as e:\n",
    "                log_msg(f\"  Warning: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if len(tissue_ratios) < 100:\n",
    "            log_msg(\"  Insufficient data, using default: 0.5\")\n",
    "            return 0.5\n",
    "        \n",
    "        # Store calibration data\n",
    "        self.calibration_data['tissue_percentages'] = tissue_ratios\n",
    "        \n",
    "        # Multi-method consensus\n",
    "        tissue_array = np.array(tissue_ratios)\n",
    "        \n",
    "        # Method A: 15th percentile\n",
    "        method_a = float(np.percentile(tissue_array, 15))\n",
    "        \n",
    "        # Method B: Otsu on histogram\n",
    "        hist, bins = np.histogram(tissue_array, bins=50)\n",
    "        bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "        \n",
    "        # Method C: Mean - std\n",
    "        method_c = max(0.1, tissue_array.mean() - tissue_array.std())\n",
    "        \n",
    "        # Consensus\n",
    "        consensus = np.median([method_a, method_c])\n",
    "        consensus = max(0.3, min(consensus, 0.7))\n",
    "        \n",
    "        self.results['tissue_threshold'] = {\n",
    "            'optimal': float(consensus),\n",
    "            'method_a': method_a,\n",
    "            'method_c': method_c,\n",
    "            'method': 'consensus'\n",
    "        }\n",
    "        \n",
    "        log_msg(f\"  ✅ Tissue threshold: {consensus:.3f}\")\n",
    "        return consensus\n",
    "    \n",
    "    def compute_bootstrap_stability(self, tile_size=224, n_iterations=50):\n",
    "        \"\"\"Method 4: Bootstrap for parameter stability\"\"\"\n",
    "        log_msg(\"Computing bootstrap stability...\")\n",
    "        \n",
    "        blur_scores = []\n",
    "        \n",
    "        for slide_path in self.slides[:2]:\n",
    "            try:\n",
    "                slide = openslide.OpenSlide(slide_path)\n",
    "                level = slide.get_best_level_for_downsample(1)\n",
    "                downsample = slide.level_downsamples[level]\n",
    "                width, height = slide.level_dimensions[level]\n",
    "                \n",
    "                for y in range(0, height - tile_size, tile_size):\n",
    "                    for x in range(0, width - tile_size, tile_size):\n",
    "                        if len(blur_scores) >= 200:\n",
    "                            break\n",
    "                        \n",
    "                        tile = np.array(slide.read_region(\n",
    "                            (int(x*downsample), int(y*downsample)),\n",
    "                            level,\n",
    "                            (tile_size, tile_size)\n",
    "                        ).convert(\"RGB\"))\n",
    "                        \n",
    "                        if not self._is_background(tile):\n",
    "                            blur_scores.append(self._compute_blur(tile))\n",
    "                    \n",
    "                    if len(blur_scores) >= 200:\n",
    "                        break\n",
    "                \n",
    "                slide.close()\n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if len(blur_scores) < 50:\n",
    "            return 50.0, 0.0\n",
    "        \n",
    "        # Bootstrap resampling\n",
    "        blur_array = np.array(blur_scores)\n",
    "        bootstrap_samples = [\n",
    "            np.percentile(np.random.choice(blur_array, len(blur_array), replace=True), 5)\n",
    "            for _ in range(n_iterations)\n",
    "        ]\n",
    "        \n",
    "        mean_val = np.mean(bootstrap_samples)\n",
    "        std_val = np.std(bootstrap_samples)\n",
    "        \n",
    "        self.calibration_data['bootstrap_samples'] = bootstrap_samples\n",
    "        \n",
    "        self.results['bootstrap'] = {\n",
    "            'mean': float(mean_val),\n",
    "            'std': float(std_val),\n",
    "            'cv': float(std_val / mean_val) if mean_val > 0 else 0\n",
    "        }\n",
    "        \n",
    "        log_msg(f\"  ✅ Bootstrap: {mean_val:.2f} ± {std_val:.2f}\")\n",
    "        return mean_val, std_val\n",
    "    \n",
    "    def compute_stain_statistics(self, tile_size=224):\n",
    "        \"\"\"Method 5: Stain normalization targets\"\"\"\n",
    "        log_msg(\"Computing stain normalization statistics...\")\n",
    "        \n",
    "        tiles = []\n",
    "        \n",
    "        for slide_path in self.slides[:3]:\n",
    "            try:\n",
    "                slide = openslide.OpenSlide(slide_path)\n",
    "                level = slide.get_best_level_for_downsample(1)\n",
    "                downsample = slide.level_downsamples[level]\n",
    "                width, height = slide.level_dimensions[level]\n",
    "                \n",
    "                for y in range(0, height - tile_size, tile_size):\n",
    "                    for x in range(0, width - tile_size, tile_size):\n",
    "                        if len(tiles) >= 200:\n",
    "                            break\n",
    "                        \n",
    "                        tile = np.array(slide.read_region(\n",
    "                            (int(x*downsample), int(y*downsample)),\n",
    "                            level,\n",
    "                            (tile_size, tile_size)\n",
    "                        ).convert(\"RGB\"))\n",
    "                        \n",
    "                        if not self._is_background(tile):\n",
    "                            mask = self._compute_tissue_mask(tile)\n",
    "                            if mask.sum() / mask.size >= 0.3:\n",
    "                                tiles.append(tile.astype(np.float32) / 255.0)\n",
    "                    \n",
    "                    if len(tiles) >= 200:\n",
    "                        break\n",
    "                \n",
    "                slide.close()\n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if len(tiles) < 20:\n",
    "            # Default H&E values\n",
    "            means = np.array([0.7, 0.55, 0.65])\n",
    "            stds = np.array([0.15, 0.15, 0.15])\n",
    "        else:\n",
    "            means_list = [t.mean(axis=(0, 1)) for t in tiles]\n",
    "            stds_list = [t.std(axis=(0, 1)) for t in tiles]\n",
    "            means = np.mean(means_list, axis=0)\n",
    "            stds = np.mean(stds_list, axis=0)\n",
    "            \n",
    "            self.calibration_data['stain_means'] = means.tolist()\n",
    "            self.calibration_data['stain_stds'] = stds.tolist()\n",
    "        \n",
    "        self.results['stain_normalization'] = {\n",
    "            'means': means.tolist(),\n",
    "            'stds': stds.tolist()\n",
    "        }\n",
    "        \n",
    "        log_msg(f\"  ✅ Stain stats: RGB means = {means.round(3)}\")\n",
    "        return means, stds\n",
    "    \n",
    "    def run_full_optimization(self, tile_size=224):\n",
    "        \"\"\"Run all 5 optimization methods\"\"\"\n",
    "        log_msg(\"\\n\" + \"=\"*80)\n",
    "        log_msg(\"RUNNING FULL PARAMETER OPTIMIZATION\")\n",
    "        log_msg(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        n_tiles = self.optimize_tile_count(tile_size)\n",
    "        blur_th = self.optimize_blur_threshold(tile_size)\n",
    "        tissue_th = self.optimize_tissue_threshold(tile_size)\n",
    "        boot_mean, boot_std = self.compute_bootstrap_stability(tile_size)\n",
    "        stain_mean, stain_std = self.compute_stain_statistics(tile_size)\n",
    "        \n",
    "        params = {\n",
    "            'tile_size': tile_size,\n",
    "            'n_tiles': n_tiles,\n",
    "            'blur_threshold': blur_th,\n",
    "            'tissue_threshold': tissue_th,\n",
    "            'stain_means': stain_mean.tolist(),\n",
    "            'stain_stds': stain_std.tolist()\n",
    "        }\n",
    "        \n",
    "        return params\n",
    "    \n",
    "    def save_results(self, output_dir):\n",
    "        \"\"\"Save optimization results\"\"\"\n",
    "        # Save optimization results\n",
    "        with open(f\"{output_dir}/optimization_results.json\", 'w') as f:\n",
    "            json.dump({\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'random_seed': RANDOM_SEED,\n",
    "                **self.results\n",
    "            }, f, indent=2)\n",
    "        \n",
    "        # Save calibration data\n",
    "        with open(f\"{output_dir}/calibration_data.json\", 'w') as f:\n",
    "            # Convert numpy arrays to lists\n",
    "            calib_data_serializable = {}\n",
    "            for key, value in self.calibration_data.items():\n",
    "                if isinstance(value, np.ndarray):\n",
    "                    calib_data_serializable[key] = value.tolist()\n",
    "                elif isinstance(value, list) and len(value) > 0 and isinstance(value[0], np.ndarray):\n",
    "                    calib_data_serializable[key] = [v.tolist() for v in value]\n",
    "                else:\n",
    "                    calib_data_serializable[key] = value\n",
    "            \n",
    "            json.dump(calib_data_serializable, f, indent=2)\n",
    "        \n",
    "        log_msg(\"✅ Optimization results saved\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PART 2: ADVANCED PATCH QUALITY CONTROL\n",
    "# ============================================================\n",
    "\n",
    "class AdvancedPatchQC:\n",
    "    \"\"\"\n",
    "    Multi-factor patch quality assessment:\n",
    "    - Tissue content\n",
    "    - Focus quality (blur)\n",
    "    - Artifact detection (pen marks, folds, dust)\n",
    "    - Information content (entropy, edges)\n",
    "    - Representativeness (color diversity)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, weights=None):\n",
    "        self.weights = weights or {\n",
    "            'tissue': 0.25,\n",
    "            'focus': 0.20,\n",
    "            'artifact': 0.20,\n",
    "            'information': 0.20,\n",
    "            'representativeness': 0.15\n",
    "        }\n",
    "    \n",
    "    def tissue_score(self, patch, mask):\n",
    "        \"\"\"Tissue content score\"\"\"\n",
    "        return mask.sum() / mask.size\n",
    "    \n",
    "    def focus_score(self, patch):\n",
    "        \"\"\"Focus quality (inverse blur)\"\"\"\n",
    "        gray = rgb2gray(patch)\n",
    "        lap_var = laplace(gray).var()\n",
    "        # Normalize to 0-1\n",
    "        return min(1.0, lap_var / 100.0)\n",
    "    \n",
    "    def artifact_score(self, patch):\n",
    "        \"\"\"Detect artifacts (pen marks, folds)\"\"\"\n",
    "        hsv = rgb2hsv(patch)\n",
    "        \n",
    "        # Pen mark detection (blue/green markers)\n",
    "        pen_mask = ((hsv[:,:,0] > 0.4) & (hsv[:,:,0] < 0.7)) & (hsv[:,:,1] > 0.5)\n",
    "        pen_ratio = pen_mask.sum() / pen_mask.size\n",
    "        \n",
    "        # Fold detection (high edge density)\n",
    "        gray = rgb2gray(patch)\n",
    "        edges = cv2.Canny((gray * 255).astype(np.uint8), 50, 150)\n",
    "        edge_density = edges.sum() / edges.size\n",
    "        \n",
    "        # Penalty for artifacts\n",
    "        artifact_penalty = pen_ratio * 0.5 + min(edge_density / 0.1, 1.0) * 0.5\n",
    "        return max(0, 1.0 - artifact_penalty)\n",
    "    \n",
    "    def information_score(self, patch):\n",
    "        \"\"\"Information content (entropy + edges)\"\"\"\n",
    "        gray = rgb2gray(patch)\n",
    "        \n",
    "        # Shannon entropy\n",
    "        hist, _ = np.histogram(gray, bins=32, range=(0, 1))\n",
    "        hist = hist / (hist.sum() + 1e-8)\n",
    "        entropy = -np.sum(hist * np.log(hist + 1e-8))\n",
    "        entropy_norm = entropy / np.log(32)\n",
    "        \n",
    "        # Edge density\n",
    "        edges = cv2.Canny((gray * 255).astype(np.uint8), 50, 150)\n",
    "        edge_score = min(edges.sum() / edges.size / 0.05, 1.0)\n",
    "        \n",
    "        return 0.7 * entropy_norm + 0.3 * edge_score\n",
    "    \n",
    "    def representativeness_score(self, patch, slide_color_centroid):\n",
    "        \"\"\"Color representativeness relative to slide\"\"\"\n",
    "        if slide_color_centroid is None:\n",
    "            return 0.5\n",
    "        \n",
    "        patch_centroid = patch.reshape(-1, 3).mean(axis=0) / 255.0\n",
    "        distance = np.linalg.norm(patch_centroid - slide_color_centroid)\n",
    "        \n",
    "        # Closer = more representative\n",
    "        return np.exp(-distance / 0.3)\n",
    "    \n",
    "    def compute_quality_score(self, patch, mask, slide_color_centroid=None):\n",
    "        \"\"\"Aggregate quality score\"\"\"\n",
    "        scores = {\n",
    "            'tissue': self.tissue_score(patch, mask),\n",
    "            'focus': self.focus_score(patch),\n",
    "            'artifact': self.artifact_score(patch),\n",
    "            'information': self.information_score(patch),\n",
    "            'representativeness': self.representativeness_score(patch, slide_color_centroid)\n",
    "        }\n",
    "        \n",
    "        # Weighted sum\n",
    "        total_score = sum(scores[k] * self.weights[k] for k in scores)\n",
    "        \n",
    "        return total_score, scores\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PART 3: ENCODER WRAPPERS\n",
    "# ============================================================\n",
    "\n",
    "class ResNet50Encoder:\n",
    "    \"\"\"ResNet-50 ImageNet pretrained (baseline)\"\"\"\n",
    "    \n",
    "    def __init__(self, device='cuda'):\n",
    "        log_msg(\"  Loading ResNet-50 (ImageNet)...\")\n",
    "        self.device = device\n",
    "        self.name = \"ResNet50-ImageNet\"\n",
    "        \n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.model = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.model = self.model.to(device).eval()\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        self.feat_dim = 2048\n",
    "        log_msg(\"    ✅ ResNet-50 loaded\")\n",
    "    \n",
    "    def extract_features(self, patches, batch_size=32):\n",
    "        \"\"\"Extract features from patches\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        for i in range(0, len(patches), batch_size):\n",
    "            batch = patches[i:i+batch_size]\n",
    "            \n",
    "            try:\n",
    "                batch_tensor = torch.stack([\n",
    "                    self.transform(Image.fromarray(p)) for p in batch\n",
    "                ]).to(self.device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    feat = self.model(batch_tensor).squeeze(-1).squeeze(-1)\n",
    "                    features.append(feat.cpu().numpy())\n",
    "            except Exception as e:\n",
    "                log_msg(f\"    ⚠️ Batch extraction failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not features:\n",
    "            return None\n",
    "        \n",
    "        return np.vstack(features)\n",
    "\n",
    "\n",
    "class CTransPathEncoder:\n",
    "    \"\"\"CTransPath domain-specific encoder\"\"\"\n",
    "    \n",
    "    def __init__(self, weights_path, device='cuda'):\n",
    "        log_msg(\"  Loading CTransPath...\")\n",
    "        self.device = device\n",
    "        self.name = \"CTransPath\"\n",
    "        \n",
    "        try:\n",
    "            if os.path.exists(weights_path):\n",
    "                checkpoint = torch.load(weights_path, map_location='cpu')\n",
    "                state_dict = checkpoint.get('model', checkpoint.get('state_dict', checkpoint))\n",
    "                \n",
    "                self.model = timm.create_model(\n",
    "                    \"swin_tiny_patch4_window7_224\",\n",
    "                    pretrained=False,\n",
    "                    num_classes=0,\n",
    "                    global_pool='avg'\n",
    "                )\n",
    "                self.model.load_state_dict(state_dict, strict=False)\n",
    "                log_msg(\"    ✅ CTransPath loaded from checkpoint\")\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Weights not found: {weights_path}\")\n",
    "        except Exception as e:\n",
    "            log_msg(f\"    ⚠️ Checkpoint load failed: {e}\")\n",
    "            log_msg(\"    ✅ Using Swin-Tiny fallback\")\n",
    "            self.model = timm.create_model(\n",
    "                \"swin_tiny_patch4_window7_224\",\n",
    "                pretrained=True,\n",
    "                num_classes=0,\n",
    "                global_pool='avg'\n",
    "            )\n",
    "        \n",
    "        self.model = self.model.to(device).eval()\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        self.feat_dim = 768\n",
    "    \n",
    "    def extract_features(self, patches, batch_size=32):\n",
    "        \"\"\"Extract features\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        for i in range(0, len(patches), batch_size):\n",
    "            batch = patches[i:i+batch_size]\n",
    "            \n",
    "            try:\n",
    "                batch_tensor = torch.stack([\n",
    "                    self.transform(Image.fromarray(p)) for p in batch\n",
    "                ]).to(self.device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    feat = self.model(batch_tensor)\n",
    "                    features.append(feat.cpu().numpy())\n",
    "            except Exception as e:\n",
    "                log_msg(f\"    ⚠️ Batch extraction failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not features:\n",
    "            return None\n",
    "        \n",
    "        return np.vstack(features)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PART 4: FEATURE QUALITY EVALUATORS\n",
    "# ============================================================\n",
    "\n",
    "class StabilityEvaluator:\n",
    "    \"\"\"Evaluate feature stability across multiple samplings\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_stability(embeddings_dict, slide_ids):\n",
    "        \"\"\"\n",
    "        Compute per-slide stability across seeds\n",
    "        \n",
    "        Args:\n",
    "            embeddings_dict: {seed: {slide_id: embedding}}\n",
    "            slide_ids: List of slide IDs\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with stability metrics\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        seeds = list(embeddings_dict.keys())\n",
    "        \n",
    "        for slide_id in slide_ids:\n",
    "            embeddings = []\n",
    "            for seed in seeds:\n",
    "                if slide_id in embeddings_dict[seed]:\n",
    "                    embeddings.append(embeddings_dict[seed][slide_id])\n",
    "            \n",
    "            if len(embeddings) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Pairwise cosine similarities\n",
    "            similarities = []\n",
    "            for i in range(len(embeddings)):\n",
    "                for j in range(i+1, len(embeddings)):\n",
    "                    sim = 1 - cosine(embeddings[i], embeddings[j])\n",
    "                    similarities.append(sim)\n",
    "            \n",
    "            # Confidence score\n",
    "            variance = np.var(similarities)\n",
    "            confidence = 1.0 / (1.0 + variance)\n",
    "            \n",
    "            results.append({\n",
    "                'slide_id': slide_id,\n",
    "                'mean_similarity': np.mean(similarities),\n",
    "                'std_similarity': np.std(similarities),\n",
    "                'min_similarity': np.min(similarities),\n",
    "                'max_similarity': np.max(similarities),\n",
    "                'confidence': confidence,\n",
    "                'n_samplings': len(embeddings)\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "class RedundancyEvaluator:\n",
    "    \"\"\"Evaluate feature redundancy\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_redundancy(features):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: (N_slides, feat_dim)\n",
    "        \n",
    "        Returns:\n",
    "            dict with redundancy metrics\n",
    "        \"\"\"\n",
    "        # Correlation analysis\n",
    "        corr_matrix = np.corrcoef(features.T)\n",
    "        upper_tri = np.triu_indices_from(corr_matrix, k=1)\n",
    "        high_corr = np.sum(np.abs(corr_matrix[upper_tri]) > 0.8)\n",
    "        total_pairs = len(upper_tri[0])\n",
    "        redundancy_ratio = high_corr / total_pairs\n",
    "        \n",
    "        # PCA effective dimension\n",
    "        pca = PCA()\n",
    "        pca.fit(features)\n",
    "        cumsum_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "        n_90 = np.argmax(cumsum_var >= 0.90) + 1\n",
    "        n_95 = np.argmax(cumsum_var >= 0.95) + 1\n",
    "        \n",
    "        return {\n",
    "            'redundancy_ratio': redundancy_ratio,\n",
    "            'mean_abs_correlation': np.mean(np.abs(corr_matrix[upper_tri])),\n",
    "            'pca_n_components_90': n_90,\n",
    "            'pca_n_components_95': n_95,\n",
    "            'effective_dim_ratio_90': n_90 / features.shape[1],\n",
    "            'effective_dim_ratio_95': n_95 / features.shape[1]\n",
    "        }\n",
    "\n",
    "\n",
    "class SeparabilityEvaluator:\n",
    "    \"\"\"Evaluate feature separability\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_separability(features, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: (N, feat_dim)\n",
    "            labels: (N,) categorical labels\n",
    "        \n",
    "        Returns:\n",
    "            dict with separability metrics\n",
    "        \"\"\"\n",
    "        # Remove NaN labels\n",
    "        valid_idx = ~pd.isna(labels)\n",
    "        features = features[valid_idx]\n",
    "        labels = labels[valid_idx]\n",
    "        \n",
    "        if len(np.unique(labels)) < 2 or len(features) < 10:\n",
    "            return None\n",
    "        \n",
    "        # Silhouette score\n",
    "        silhouette = silhouette_score(features, labels, metric='cosine')\n",
    "        \n",
    "        # Davies-Bouldin index\n",
    "        davies_bouldin = davies_bouldin_score(features, labels)\n",
    "        \n",
    "        # kNN leave-one-out\n",
    "        knn = KNeighborsClassifier(n_neighbors=5)\n",
    "        loo = LeaveOneOut()\n",
    "        \n",
    "        predictions, ground_truth = [], []\n",
    "        for train_idx, test_idx in loo.split(features):\n",
    "            knn.fit(features[train_idx], labels[train_idx])\n",
    "            pred = knn.predict(features[test_idx])\n",
    "            predictions.append(pred[0])\n",
    "            ground_truth.append(labels[test_idx][0])\n",
    "        \n",
    "        accuracy = np.mean(np.array(predictions) == np.array(ground_truth))\n",
    "        \n",
    "        return {\n",
    "            'silhouette_score': silhouette,\n",
    "            'davies_bouldin_index': davies_bouldin,\n",
    "            'knn_loo_accuracy': accuracy,\n",
    "            'n_classes': len(np.unique(labels))\n",
    "        }\n",
    "\n",
    "\n",
    "class HeterogeneityAnalyzer:\n",
    "    \"\"\"Quantify slide-level heterogeneity\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_heterogeneity(patch_features):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patch_features: (N_patches, feat_dim)\n",
    "        \n",
    "        Returns:\n",
    "            heterogeneity_score, metrics_dict\n",
    "        \"\"\"\n",
    "        if len(patch_features) < 10:\n",
    "            return 0.0, {}\n",
    "        \n",
    "        # Pairwise distances\n",
    "        distances = pdist(patch_features, metric='cosine')\n",
    "        mean_distance = np.mean(distances)\n",
    "        std_distance = np.std(distances)\n",
    "        \n",
    "        # Estimate cluster count\n",
    "        inertias = []\n",
    "        k_range = range(2, min(10, len(patch_features)//10))\n",
    "        for k in k_range:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            kmeans.fit(patch_features)\n",
    "            inertias.append(kmeans.inertia_)\n",
    "        \n",
    "        if len(inertias) >= 2:\n",
    "            diffs = np.diff(inertias)\n",
    "            elbow_k = np.argmin(diffs) + 2\n",
    "        else:\n",
    "            elbow_k = 2\n",
    "        \n",
    "        # Silhouette for estimated clusters\n",
    "        if elbow_k < len(patch_features):\n",
    "            kmeans = KMeans(n_clusters=elbow_k, random_state=42, n_init=10)\n",
    "            labels = kmeans.fit_predict(patch_features)\n",
    "            silhouette = silhouette_score(patch_features, labels, metric='cosine')\n",
    "        else:\n",
    "            silhouette = 0.0\n",
    "        \n",
    "        # Feature entropy\n",
    "        pca = PCA(n_components=min(50, patch_features.shape[1]))\n",
    "        pca.fit(patch_features)\n",
    "        variance_ratios = pca.explained_variance_ratio_\n",
    "        entropy = -np.sum(variance_ratios * np.log(variance_ratios + 1e-8))\n",
    "        \n",
    "        metrics = {\n",
    "            'mean_distance': float(mean_distance),\n",
    "            'std_distance': float(std_distance),\n",
    "            'estimated_clusters': int(elbow_k),\n",
    "            'silhouette': float(silhouette),\n",
    "            'feature_entropy': float(entropy)\n",
    "        }\n",
    "        \n",
    "        # Aggregate score\n",
    "        heterogeneity_score = (\n",
    "            0.3 * mean_distance +\n",
    "            0.2 * (elbow_k / 10.0) +\n",
    "            0.3 * (1.0 - silhouette) +\n",
    "            0.2 * (entropy / 4.0)\n",
    "        )\n",
    "        \n",
    "        return float(heterogeneity_score), metrics\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PART 5: MAIN PIPELINE ORCHESTRATOR\n",
    "# ============================================================\n",
    "\n",
    "class WSIFeatureQC:\n",
    "    \"\"\"Main pipeline orchestrator\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.optimized_params = None\n",
    "        self.encoders = {}\n",
    "        self.qc = AdvancedPatchQC()\n",
    "    \n",
    "    def initialize_encoders(self):\n",
    "        \"\"\"Initialize all encoders\"\"\"\n",
    "        log_msg(\"\\n\" + \"=\"*80)\n",
    "        log_msg(\"INITIALIZING ENCODERS\")\n",
    "        log_msg(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # ResNet-50\n",
    "        self.encoders['resnet50'] = ResNet50Encoder(device=DEVICE)\n",
    "        \n",
    "        # CTransPath\n",
    "        if os.path.exists(CTRANSPATH_WEIGHTS):\n",
    "            self.encoders['ctranspath'] = CTransPathEncoder(\n",
    "                CTRANSPATH_WEIGHTS, \n",
    "                device=DEVICE\n",
    "            )\n",
    "        \n",
    "        log_msg(f\"\\n✅ Initialized {len(self.encoders)} encoders\")\n",
    "    \n",
    "    def run_optimization(self, calibration_slides):\n",
    "        \"\"\"Run parameter optimization\"\"\"\n",
    "        log_msg(\"\\n\" + \"=\"*80)\n",
    "        log_msg(\"STEP 1: PARAMETER OPTIMIZATION\")\n",
    "        log_msg(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        optimizer = MultiMethodOptimizer(calibration_slides)\n",
    "        self.optimized_params = optimizer.run_full_optimization()\n",
    "        optimizer.save_results(OUTPUT_DIR)\n",
    "        \n",
    "        # Save params\n",
    "        with open(f\"{OUTPUT_DIR}/optimized_params.json\", 'w') as f:\n",
    "            json.dump(self.optimized_params, f, indent=2)\n",
    "        \n",
    "        log_msg(\"\\n✅ Optimization complete\")\n",
    "        return self.optimized_params\n",
    "    \n",
    "    def extract_patches(self, slide_path, seed=42):\n",
    "        \"\"\"Extract high-quality patches from slide\"\"\"\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        slide = openslide.OpenSlide(slide_path)\n",
    "        level = slide.get_best_level_for_downsample(1)\n",
    "        downsample = slide.level_downsamples[level]\n",
    "        width, height = slide.level_dimensions[level]\n",
    "        \n",
    "        tile_size = self.optimized_params['tile_size']\n",
    "        n_tiles = self.optimized_params['n_tiles']\n",
    "        blur_th = self.optimized_params['blur_threshold']\n",
    "        tissue_th = self.optimized_params['tissue_threshold']\n",
    "        \n",
    "        # Generate tissue mask at thumbnail resolution\n",
    "        thumb_w, thumb_h = width // 32, height // 32\n",
    "        thumbnail = slide.get_thumbnail((thumb_w, thumb_h))\n",
    "        thumbnail_arr = np.array(thumbnail)\n",
    "        \n",
    "        hsv = rgb2hsv(thumbnail_arr)\n",
    "        thresh = threshold_otsu(hsv[:,:,1])\n",
    "        tissue_mask = hsv[:,:,1] > thresh\n",
    "        tissue_mask = remove_small_objects(tissue_mask, min_size=50)\n",
    "        tissue_mask = binary_closing(tissue_mask, disk(3))\n",
    "        \n",
    "        # Get tissue coordinates (downsampled)\n",
    "        tissue_coords = np.argwhere(tissue_mask > 0)\n",
    "        if len(tissue_coords) == 0:\n",
    "            slide.close()\n",
    "            return []\n",
    "        \n",
    "        # Randomly sample coordinates\n",
    "        np.random.shuffle(tissue_coords)\n",
    "        \n",
    "        patches = []\n",
    "        attempts = 0\n",
    "        max_attempts = min(len(tissue_coords), n_tiles * 10)\n",
    "        \n",
    "        for coord in tissue_coords[:max_attempts]:\n",
    "            if len(patches) >= n_tiles:\n",
    "                break\n",
    "            \n",
    "            # Scale coordinates\n",
    "            y_thumb, x_thumb = coord\n",
    "            y = y_thumb * 32\n",
    "            x = x_thumb * 32\n",
    "            \n",
    "            if y + tile_size > height or x + tile_size > width:\n",
    "                continue\n",
    "            \n",
    "            attempts += 1\n",
    "            \n",
    "            try:\n",
    "                patch = np.array(slide.read_region(\n",
    "                    (int(x*downsample), int(y*downsample)),\n",
    "                    level,\n",
    "                    (tile_size, tile_size)\n",
    "                ).convert(\"RGB\"))\n",
    "                \n",
    "                # Quality checks\n",
    "                if np.mean(patch) > 220:\n",
    "                    continue\n",
    "                \n",
    "                # Tissue mask\n",
    "                gray = np.mean(patch, axis=2)\n",
    "                mask_thresh = threshold_otsu(gray) if gray.std() > 1 else 200\n",
    "                mask = gray < mask_thresh\n",
    "                mask = remove_small_objects(mask, 500)\n",
    "                mask = binary_dilation(mask, disk(3))\n",
    "                \n",
    "                tissue_ratio = mask.sum() / mask.size\n",
    "                if tissue_ratio < tissue_th:\n",
    "                    continue\n",
    "                \n",
    "                # Blur check\n",
    "                blur_score = laplace(rgb2gray(patch)).var()\n",
    "                if blur_score < blur_th:\n",
    "                    continue\n",
    "                \n",
    "                patches.append(patch)\n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        slide.close()\n",
    "        return patches\n",
    "    \n",
    "    def process_slide(self, slide_path, slide_id, encoder_name, seeds=RANDOM_SEEDS):\n",
    "        \"\"\"Process single slide with multi-seed sampling\"\"\"\n",
    "        log_msg(f\"  Processing {slide_id} with {encoder_name}...\")\n",
    "        \n",
    "        encoder = self.encoders[encoder_name]\n",
    "        seed_embeddings = []\n",
    "        \n",
    "        for seed in seeds:\n",
    "            patches = self.extract_patches(slide_path, seed=seed)\n",
    "            \n",
    "            if len(patches) < 100:\n",
    "                log_msg(f\"    ⚠️ Seed {seed}: Only {len(patches)} patches\")\n",
    "                continue\n",
    "            \n",
    "            # Extract features\n",
    "            features = encoder.extract_features(patches)\n",
    "            \n",
    "            if features is None:\n",
    "                continue\n",
    "            \n",
    "            # Aggregate\n",
    "            slide_emb = np.concatenate([\n",
    "                features.mean(axis=0),\n",
    "                features.std(axis=0)\n",
    "            ])\n",
    "            \n",
    "            seed_embeddings.append(slide_emb)\n",
    "        \n",
    "        if len(seed_embeddings) < 2:\n",
    "            return None\n",
    "        \n",
    "        return seed_embeddings\n",
    "    \n",
    "    def run_pipeline(self, slide_paths, slide_ids):\n",
    "        \"\"\"Run complete pipeline\"\"\"\n",
    "        log_msg(\"\\n\" + \"=\"*80)\n",
    "        log_msg(\"STEP 2: FEATURE EXTRACTION\")\n",
    "        log_msg(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        all_results = {}\n",
    "        \n",
    "        for encoder_name in self.encoders:\n",
    "            log_msg(f\"\\nEncoder: {encoder_name}\")\n",
    "            \n",
    "            embeddings_by_seed = {seed: {} for seed in RANDOM_SEEDS}\n",
    "            \n",
    "            for slide_path, slide_id in zip(slide_paths, slide_ids):\n",
    "                seed_embs = self.process_slide(\n",
    "                    slide_path, slide_id, encoder_name\n",
    "                )\n",
    "                \n",
    "                if seed_embs is None:\n",
    "                    continue\n",
    "                \n",
    "                for i, seed in enumerate(RANDOM_SEEDS[:len(seed_embs)]):\n",
    "                    embeddings_by_seed[seed][slide_id] = seed_embs[i]\n",
    "            \n",
    "            all_results[encoder_name] = embeddings_by_seed\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def evaluate_features(self, all_results, slide_ids, labels=None):\n",
    "        \"\"\"Evaluate feature quality\"\"\"\n",
    "        log_msg(\"\\n\" + \"=\"*80)\n",
    "        log_msg(\"STEP 3: FEATURE QUALITY EVALUATION\")\n",
    "        log_msg(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        evaluation_results = {}\n",
    "        \n",
    "        for encoder_name, embeddings_by_seed in all_results.items():\n",
    "            log_msg(f\"\\nEvaluating {encoder_name}...\")\n",
    "            \n",
    "            # Stability\n",
    "            stability_df = StabilityEvaluator.compute_stability(\n",
    "                embeddings_by_seed, slide_ids\n",
    "            )\n",
    "            \n",
    "            # Redundancy (use first seed)\n",
    "            first_seed = RANDOM_SEEDS[0]\n",
    "            features_matrix = np.array([\n",
    "                embeddings_by_seed[first_seed][sid]\n",
    "                for sid in slide_ids\n",
    "                if sid in embeddings_by_seed[first_seed]\n",
    "            ])\n",
    "            \n",
    "            redundancy = RedundancyEvaluator.compute_redundancy(features_matrix)\n",
    "            \n",
    "            # Separability (if labels provided)\n",
    "            separability = None\n",
    "            if labels is not None:\n",
    "                separability = SeparabilityEvaluator.compute_separability(\n",
    "                    features_matrix, labels\n",
    "                )\n",
    "            \n",
    "            evaluation_results[encoder_name] = {\n",
    "                'stability': stability_df,\n",
    "                'redundancy': redundancy,\n",
    "                'separability': separability\n",
    "            }\n",
    "            \n",
    "            log_msg(f\"  ✅ Stability: {stability_df['mean_similarity'].mean():.3f}\")\n",
    "            log_msg(f\"  ✅ Redundancy: {redundancy['redundancy_ratio']:.3f}\")\n",
    "            if separability:\n",
    "                log_msg(f\"  ✅ Separability: {separability['silhouette_score']:.3f}\")\n",
    "        \n",
    "        return evaluation_results\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    # Get slide paths\n",
    "    slide_files = [f for f in os.listdir(SVS_DIR) if f.lower().endswith('.svs')]\n",
    "    \n",
    "    if len(slide_files) == 0:\n",
    "        log_msg(\"❌ No SVS files found!\")\n",
    "        return\n",
    "    \n",
    "    np.random.shuffle(slide_files)\n",
    "    \n",
    "    # Split: 10% calibration, rest for processing\n",
    "    n_calib = max(1, int(0.1 * len(slide_files)))\n",
    "    calib_files = slide_files[:n_calib]\n",
    "    proc_files = slide_files[:10]  # Process first 10 for demo\n",
    "    \n",
    "    calib_paths = [os.path.join(SVS_DIR, f) for f in calib_files]\n",
    "    proc_paths = [os.path.join(SVS_DIR, f) for f in proc_files]\n",
    "    proc_ids = [Path(f).stem for f in proc_files]\n",
    "    \n",
    "    log_msg(f\"Calibration slides: {n_calib}\")\n",
    "    log_msg(f\"Processing slides: {len(proc_files)}\")\n",
    "    \n",
    "    # Initialize pipeline\n",
    "    pipeline = WSIFeatureQC(config={})\n",
    "    \n",
    "    # Step 1: Optimize parameters\n",
    "    params = pipeline.run_optimization(calib_paths)\n",
    "    \n",
    "    # Step 2: Initialize encoders\n",
    "    pipeline.initialize_encoders()\n",
    "    \n",
    "    # Step 3: Extract features\n",
    "    all_results = pipeline.run_pipeline(proc_paths, proc_ids)\n",
    "    \n",
    "    # Step 4: Evaluate\n",
    "    evaluation_results = pipeline.evaluate_features(all_results, proc_ids)\n",
    "    \n",
    "    # Save results\n",
    "    log_msg(\"\\n\" + \"=\"*80)\n",
    "    log_msg(\"SAVING RESULTS\")\n",
    "    log_msg(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    with open(f\"{OUTPUT_DIR}/evaluation_results.json\", 'w') as f:\n",
    "        # Convert DataFrames to dicts for JSON serialization\n",
    "        eval_serializable = {}\n",
    "        for enc_name, results in evaluation_results.items():\n",
    "            eval_serializable[enc_name] = {\n",
    "                'stability': results['stability'].to_dict('records'),\n",
    "                'redundancy': results['redundancy'],\n",
    "                'separability': results['separability']\n",
    "            }\n",
    "        json.dump(eval_serializable, f, indent=2)\n",
    "    \n",
    "    log_msg(\"✅ Results saved\")\n",
    "    \n",
    "    log_msg(\"\\n\" + \"=\"*80)\n",
    "    log_msg(\"✅ PIPELINE COMPLETE\")\n",
    "    log_msg(\"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PART 6: BASELINE IMPLEMENTATIONS FOR COMPARISON\n",
    "# ============================================================\n",
    "\n",
    "class NaiveCNNBaseline:\n",
    "    \"\"\"\n",
    "    Baseline 1: Naive CNN approach\n",
    "    - Uniform tiling (no quality control)\n",
    "    - ResNet-50 features\n",
    "    - Simple mean pooling\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, device='cuda'):\n",
    "        self.name = \"Naive-CNN\"\n",
    "        self.device = device\n",
    "        \n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.model = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.model = self.model.to(device).eval()\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def extract_patches_naive(self, slide_path, n_patches=1000, tile_size=224):\n",
    "        \"\"\"Naive uniform tiling - NO quality control\"\"\"\n",
    "        slide = openslide.OpenSlide(slide_path)\n",
    "        level = slide.get_best_level_for_downsample(1)\n",
    "        downsample = slide.level_downsamples[level]\n",
    "        width, height = slide.level_dimensions[level]\n",
    "        \n",
    "        patches = []\n",
    "        step = tile_size\n",
    "        \n",
    "        for y in range(0, height - tile_size, step):\n",
    "            for x in range(0, width - tile_size, step):\n",
    "                if len(patches) >= n_patches:\n",
    "                    break\n",
    "                \n",
    "                try:\n",
    "                    patch = np.array(slide.read_region(\n",
    "                        (int(x*downsample), int(y*downsample)),\n",
    "                        level,\n",
    "                        (tile_size, tile_size)\n",
    "                    ).convert(\"RGB\"))\n",
    "                    \n",
    "                    # Only reject pure white background\n",
    "                    if np.mean(patch) < 240:\n",
    "                        patches.append(patch)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            if len(patches) >= n_patches:\n",
    "                break\n",
    "        \n",
    "        slide.close()\n",
    "        return patches\n",
    "    \n",
    "    def process_slide(self, slide_path, seed=42):\n",
    "        \"\"\"Extract features - single seed only\"\"\"\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        patches = self.extract_patches_naive(slide_path)\n",
    "        \n",
    "        if len(patches) < 100:\n",
    "            return None\n",
    "        \n",
    "        # Extract features\n",
    "        features = []\n",
    "        for i in range(0, len(patches), 32):\n",
    "            batch = patches[i:i+32]\n",
    "            batch_tensor = torch.stack([\n",
    "                self.transform(Image.fromarray(p)) for p in batch\n",
    "            ]).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                feat = self.model(batch_tensor).squeeze(-1).squeeze(-1)\n",
    "                features.append(feat.cpu().numpy())\n",
    "        \n",
    "        features = np.vstack(features)\n",
    "        \n",
    "        # Simple mean pooling (no std)\n",
    "        return features.mean(axis=0)\n",
    "\n",
    "\n",
    "class AttentionMILBaseline:\n",
    "    \"\"\"\n",
    "    Baseline 2: Attention-MIL approach (simplified CLAM-style)\n",
    "    - ResNet-50 features\n",
    "    - Attention-weighted aggregation\n",
    "    - Requires labels for training\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, device='cuda', feat_dim=2048, hidden_dim=256):\n",
    "        self.name = \"Attention-MIL\"\n",
    "        self.device = device\n",
    "        \n",
    "        # Feature extractor\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.feature_extractor = self.feature_extractor.to(device).eval()\n",
    "        \n",
    "        # Attention network\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(feat_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        ).to(device)\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        self.trained = False\n",
    "    \n",
    "    def extract_patch_features(self, patches):\n",
    "        \"\"\"Extract patch-level features\"\"\"\n",
    "        features = []\n",
    "        for i in range(0, len(patches), 32):\n",
    "            batch = patches[i:i+32]\n",
    "            batch_tensor = torch.stack([\n",
    "                self.transform(Image.fromarray(p)) for p in batch\n",
    "            ]).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                feat = self.feature_extractor(batch_tensor).squeeze(-1).squeeze(-1)\n",
    "                features.append(feat.cpu().numpy())\n",
    "        \n",
    "        return np.vstack(features)\n",
    "    \n",
    "    def train_attention(self, slide_features_list, labels, epochs=10):\n",
    "        \"\"\"Train attention weights (simplified)\"\"\"\n",
    "        log_msg(\"  Training attention weights...\")\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.attention.parameters(), lr=1e-4)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for features, label in zip(slide_features_list, labels):\n",
    "                features_tensor = torch.FloatTensor(features).to(self.device)\n",
    "                label_tensor = torch.FloatTensor([label]).to(self.device)\n",
    "                \n",
    "                # Attention scores\n",
    "                attention_scores = self.attention(features_tensor)\n",
    "                attention_weights = torch.softmax(attention_scores, dim=0)\n",
    "                \n",
    "                # Weighted aggregation\n",
    "                slide_emb = (features_tensor * attention_weights).sum(dim=0)\n",
    "                \n",
    "                # Simple binary classification\n",
    "                pred = slide_emb.mean()\n",
    "                loss = criterion(pred.unsqueeze(0), label_tensor)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                log_msg(f\"    Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "        \n",
    "        self.trained = True\n",
    "        log_msg(\"  ✅ Attention training complete\")\n",
    "    \n",
    "    def process_slide(self, slide_path, seed=42):\n",
    "        \"\"\"Extract features with attention pooling\"\"\"\n",
    "        if not self.trained:\n",
    "            log_msg(\"  ⚠️ Attention not trained, using uniform weights\")\n",
    "        \n",
    "        # Use naive patch extraction\n",
    "        naive = NaiveCNNBaseline(self.device)\n",
    "        patches = naive.extract_patches_naive(slide_path)\n",
    "        \n",
    "        if len(patches) < 100:\n",
    "            return None\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.extract_patch_features(patches)\n",
    "        features_tensor = torch.FloatTensor(features).to(self.device)\n",
    "        \n",
    "        # Apply attention\n",
    "        with torch.no_grad():\n",
    "            if self.trained:\n",
    "                attention_scores = self.attention(features_tensor)\n",
    "                attention_weights = torch.softmax(attention_scores, dim=0)\n",
    "            else:\n",
    "                attention_weights = torch.ones(len(features), 1).to(self.device) / len(features)\n",
    "            \n",
    "            slide_emb = (features_tensor * attention_weights).sum(dim=0)\n",
    "        \n",
    "        return slide_emb.cpu().numpy()\n",
    "\n",
    "\n",
    "class RadiomicsBaseline:\n",
    "    \"\"\"\n",
    "    Baseline 3: Classical radiomics features\n",
    "    - Hand-crafted texture features\n",
    "    - Shape features\n",
    "    - Intensity statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"Radiomics\"\n",
    "    \n",
    "    def extract_texture_features(self, patch):\n",
    "        \"\"\"Extract texture features from patch\"\"\"\n",
    "        gray = rgb2gray(patch)\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # Intensity statistics\n",
    "        features['intensity_mean'] = gray.mean()\n",
    "        features['intensity_std'] = gray.std()\n",
    "        features['intensity_min'] = gray.min()\n",
    "        features['intensity_max'] = gray.max()\n",
    "        features['intensity_range'] = gray.max() - gray.min()\n",
    "        \n",
    "        # Histogram features\n",
    "        hist, _ = np.histogram(gray, bins=32)\n",
    "        hist = hist / (hist.sum() + 1e-8)\n",
    "        features['entropy'] = -np.sum(hist * np.log(hist + 1e-8))\n",
    "        features['uniformity'] = np.sum(hist ** 2)\n",
    "        \n",
    "        # GLCM-inspired features (simplified)\n",
    "        # Horizontal differences\n",
    "        h_diff = np.abs(np.diff(gray, axis=1))\n",
    "        features['contrast'] = h_diff.mean()\n",
    "        features['homogeneity'] = 1.0 / (1.0 + h_diff.mean())\n",
    "        \n",
    "        # Gradient features\n",
    "        gy, gx = np.gradient(gray)\n",
    "        gradient_mag = np.sqrt(gx**2 + gy**2)\n",
    "        features['gradient_mean'] = gradient_mag.mean()\n",
    "        features['gradient_std'] = gradient_mag.std()\n",
    "        \n",
    "        # Edge features\n",
    "        edges = cv2.Canny((gray * 255).astype(np.uint8), 50, 150)\n",
    "        features['edge_density'] = edges.sum() / edges.size\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def process_slide(self, slide_path, seed=42):\n",
    "        \"\"\"Extract radiomics features\"\"\"\n",
    "        # Use naive patch extraction\n",
    "        naive = NaiveCNNBaseline()\n",
    "        patches = naive.extract_patches_naive(slide_path, n_patches=500)\n",
    "        \n",
    "        if len(patches) < 100:\n",
    "            return None\n",
    "        \n",
    "        # Extract features from all patches\n",
    "        all_features = []\n",
    "        for patch in patches:\n",
    "            feat_dict = self.extract_texture_features(patch)\n",
    "            all_features.append(list(feat_dict.values()))\n",
    "        \n",
    "        # Aggregate: mean and std\n",
    "        features_array = np.array(all_features)\n",
    "        slide_features = np.concatenate([\n",
    "            features_array.mean(axis=0),\n",
    "            features_array.std(axis=0)\n",
    "        ])\n",
    "        \n",
    "        return slide_features\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PART 7: FRAMEWORK COMPARISON ENGINE\n",
    "# ============================================================\n",
    "\n",
    "class FrameworkComparison:\n",
    "    \"\"\"\n",
    "    Compare your framework against baselines:\n",
    "    - Naive CNN\n",
    "    - Attention-MIL\n",
    "    - Radiomics\n",
    "    \n",
    "    Metrics:\n",
    "    - Stability\n",
    "    - Redundancy\n",
    "    - Separability\n",
    "    - Robustness\n",
    "    - Runtime\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, your_framework, device='cuda'):\n",
    "        self.your_framework = your_framework\n",
    "        self.device = device\n",
    "        \n",
    "        # Initialize baselines\n",
    "        self.baselines = {\n",
    "            'naive_cnn': NaiveCNNBaseline(device),\n",
    "            'attention_mil': AttentionMILBaseline(device),\n",
    "            'radiomics': RadiomicsBaseline()\n",
    "        }\n",
    "        \n",
    "        self.comparison_results = {}\n",
    "    \n",
    "    def extract_baseline_features(self, slide_paths, slide_ids, baseline_name, \n",
    "                                   n_seeds=1):\n",
    "        \"\"\"Extract features using a baseline method\"\"\"\n",
    "        log_msg(f\"\\n{'='*80}\")\n",
    "        log_msg(f\"BASELINE: {baseline_name.upper()}\")\n",
    "        log_msg(f\"{'='*80}\\n\")\n",
    "        \n",
    "        baseline = self.baselines[baseline_name]\n",
    "        \n",
    "        embeddings_by_seed = {seed: {} for seed in RANDOM_SEEDS[:n_seeds]}\n",
    "        \n",
    "        for slide_path, slide_id in zip(slide_paths, slide_ids):\n",
    "            log_msg(f\"  Processing {slide_id}...\")\n",
    "            \n",
    "            for seed in RANDOM_SEEDS[:n_seeds]:\n",
    "                emb = baseline.process_slide(slide_path, seed=seed)\n",
    "                \n",
    "                if emb is not None:\n",
    "                    embeddings_by_seed[seed][slide_id] = emb\n",
    "        \n",
    "        return embeddings_by_seed\n",
    "    \n",
    "    def compute_comparison_metrics(self, embeddings_dict, slide_ids, labels=None):\n",
    "        \"\"\"Compute all evaluation metrics for a method\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # 1. Stability (if multiple seeds)\n",
    "        if len(embeddings_dict) > 1:\n",
    "            stability_df = StabilityEvaluator.compute_stability(\n",
    "                embeddings_dict, slide_ids\n",
    "            )\n",
    "            metrics['stability_mean'] = stability_df['mean_similarity'].mean()\n",
    "            metrics['stability_std'] = stability_df['mean_similarity'].std()\n",
    "        else:\n",
    "            metrics['stability_mean'] = None\n",
    "            metrics['stability_std'] = None\n",
    "        \n",
    "        # 2. Redundancy\n",
    "        first_seed = list(embeddings_dict.keys())[0]\n",
    "        features_matrix = np.array([\n",
    "            embeddings_dict[first_seed][sid]\n",
    "            for sid in slide_ids\n",
    "            if sid in embeddings_dict[first_seed]\n",
    "        ])\n",
    "        \n",
    "        if len(features_matrix) > 5:\n",
    "            redundancy = RedundancyEvaluator.compute_redundancy(features_matrix)\n",
    "            metrics['redundancy_ratio'] = redundancy['redundancy_ratio']\n",
    "            metrics['pca_effective_dim_95'] = redundancy['pca_n_components_95']\n",
    "        else:\n",
    "            metrics['redundancy_ratio'] = None\n",
    "            metrics['pca_effective_dim_95'] = None\n",
    "        \n",
    "        # 3. Separability (if labels provided)\n",
    "        if labels is not None and len(features_matrix) > 5:\n",
    "            separability = SeparabilityEvaluator.compute_separability(\n",
    "                features_matrix, labels\n",
    "            )\n",
    "            if separability:\n",
    "                metrics['silhouette_score'] = separability['silhouette_score']\n",
    "                metrics['knn_accuracy'] = separability['knn_loo_accuracy']\n",
    "        else:\n",
    "            metrics['silhouette_score'] = None\n",
    "            metrics['knn_accuracy'] = None\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def run_comparison(self, slide_paths, slide_ids, labels=None):\n",
    "        \"\"\"Run complete framework comparison\"\"\"\n",
    "        log_msg(\"\\n\" + \"=\"*80)\n",
    "        log_msg(\"FRAMEWORK COMPARISON\")\n",
    "        log_msg(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # 1. Your framework (already extracted - multi-seed)\n",
    "        log_msg(\"Evaluating YOUR FRAMEWORK (multi-seed)...\")\n",
    "        # Assuming your_framework.all_results exists\n",
    "        for encoder_name in self.your_framework.encoders:\n",
    "            if hasattr(self.your_framework, 'all_results'):\n",
    "                your_embeddings = self.your_framework.all_results[encoder_name]\n",
    "                your_metrics = self.compute_comparison_metrics(\n",
    "                    your_embeddings, slide_ids, labels\n",
    "                )\n",
    "                results[f'yours_{encoder_name}'] = your_metrics\n",
    "        \n",
    "        # 2. Naive CNN baseline (single seed only)\n",
    "        naive_embeddings = self.extract_baseline_features(\n",
    "            slide_paths, slide_ids, 'naive_cnn', n_seeds=1\n",
    "        )\n",
    "        naive_metrics = self.compute_comparison_metrics(\n",
    "            naive_embeddings, slide_ids, labels\n",
    "        )\n",
    "        results['naive_cnn'] = naive_metrics\n",
    "        \n",
    "        # 3. Attention-MIL baseline (single seed)\n",
    "        # Note: Would need labels to train attention properly\n",
    "        attn_embeddings = self.extract_baseline_features(\n",
    "            slide_paths, slide_ids, 'attention_mil', n_seeds=1\n",
    "        )\n",
    "        attn_metrics = self.compute_comparison_metrics(\n",
    "            attn_embeddings, slide_ids, labels\n",
    "        )\n",
    "        results['attention_mil'] = attn_metrics\n",
    "        \n",
    "        # 4. Radiomics baseline (single seed)\n",
    "        radiomics_embeddings = self.extract_baseline_features(\n",
    "            slide_paths, slide_ids, 'radiomics', n_seeds=1\n",
    "        )\n",
    "        radiomics_metrics = self.compute_comparison_metrics(\n",
    "            radiomics_embeddings, slide_ids, labels\n",
    "        )\n",
    "        results['radiomics'] = radiomics_metrics\n",
    "        \n",
    "        self.comparison_results = results\n",
    "        return results\n",
    "    \n",
    "    def generate_comparison_table(self):\n",
    "        \"\"\"Generate comparison table for paper\"\"\"\n",
    "        log_msg(\"\\n\" + \"=\"*80)\n",
    "        log_msg(\"COMPARISON TABLE\")\n",
    "        log_msg(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # Create DataFrame\n",
    "        rows = []\n",
    "        for method_name, metrics in self.comparison_results.items():\n",
    "            row = {\n",
    "                'Method': method_name,\n",
    "                'Stability ↑': f\"{metrics['stability_mean']:.3f}\" if metrics['stability_mean'] else \"N/A\",\n",
    "                'Redundancy ↓': f\"{metrics['redundancy_ratio']:.3f}\" if metrics['redundancy_ratio'] else \"N/A\",\n",
    "                'Separability ↑': f\"{metrics['silhouette_score']:.3f}\" if metrics['silhouette_score'] else \"N/A\",\n",
    "                'kNN Acc ↑': f\"{metrics['knn_accuracy']:.3f}\" if metrics['knn_accuracy'] else \"N/A\"\n",
    "            }\n",
    "            rows.append(row)\n",
    "        \n",
    "        df = pd.DataFrame(rows)\n",
    "        \n",
    "        # Print table\n",
    "        print(df.to_string(index=False))\n",
    "        \n",
    "        # Save to CSV\n",
    "        df.to_csv(f\"{OUTPUT_DIR}/comparison_table.csv\", index=False)\n",
    "        log_msg(f\"\\n✅ Comparison table saved to {OUTPUT_DIR}/comparison_table.csv\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def statistical_significance_test(self):\n",
    "        \"\"\"Perform statistical tests (Wilcoxon signed-rank)\"\"\"\n",
    "        log_msg(\"\\n\" + \"=\"*80)\n",
    "        log_msg(\"STATISTICAL SIGNIFICANCE TESTS\")\n",
    "        log_msg(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # Compare your best method vs each baseline\n",
    "        # This would require per-slide scores\n",
    "        # For now, just report summary\n",
    "        \n",
    "        log_msg(\"Statistical tests require per-slide scores\")\n",
    "        log_msg(\"Implement Wilcoxon signed-rank test for paired comparison\")\n",
    "        \n",
    "        # TODO: Implement proper statistical testing\n",
    "        pass\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PART 8: UPDATED MAIN EXECUTION WITH COMPARISON\n",
    "# ============================================================\n",
    "\n",
    "def main_with_comparison():\n",
    "    \"\"\"Main execution with baseline comparison\"\"\"\n",
    "    \n",
    "    # Get slide paths\n",
    "    slide_files = [f for f in os.listdir(SVS_DIR) if f.lower().endswith('.svs')]\n",
    "    \n",
    "    if len(slide_files) == 0:\n",
    "        log_msg(\"❌ No SVS files found!\")\n",
    "        return\n",
    "    \n",
    "    np.random.shuffle(slide_files)\n",
    "    \n",
    "    # Split: 10% calibration, rest for processing\n",
    "    n_calib = max(1, int(0.1 * len(slide_files)))\n",
    "    calib_files = slide_files[:n_calib]\n",
    "    proc_files = slide_files[:10]  # Process first 10 for demo\n",
    "    \n",
    "    calib_paths = [os.path.join(SVS_DIR, f) for f in calib_files]\n",
    "    proc_paths = [os.path.join(SVS_DIR, f) for f in proc_files]\n",
    "    proc_ids = [Path(f).stem for f in proc_files]\n",
    "    \n",
    "    log_msg(f\"Calibration slides: {n_calib}\")\n",
    "    log_msg(f\"Processing slides: {len(proc_files)}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # YOUR FRAMEWORK\n",
    "    # ========================================\n",
    "    \n",
    "    # Initialize pipeline\n",
    "    pipeline = WSIFeatureQC(config={})\n",
    "    \n",
    "    # Step 1: Optimize parameters\n",
    "    params = pipeline.run_optimization(calib_paths)\n",
    "    \n",
    "    # Step 2: Initialize encoders\n",
    "    pipeline.initialize_encoders()\n",
    "    \n",
    "    # Step 3: Extract features\n",
    "    all_results = pipeline.run_pipeline(proc_paths, proc_ids)\n",
    "    pipeline.all_results = all_results  # Store for comparison\n",
    "    \n",
    "    # Step 4: Evaluate\n",
    "    evaluation_results = pipeline.evaluate_features(all_results, proc_ids)\n",
    "    \n",
    "    # ========================================\n",
    "    # BASELINE COMPARISON\n",
    "    # ========================================\n",
    "    \n",
    "    # Initialize comparison\n",
    "    comparator = FrameworkComparison(pipeline, device=DEVICE)\n",
    "    \n",
    "    # Run comparison\n",
    "    comparison_results = comparator.run_comparison(\n",
    "        proc_paths, proc_ids, labels=None\n",
    "    )\n",
    "    \n",
    "    # Generate comparison table\n",
    "    comparison_df = comparator.generate_comparison_table()\n",
    "    \n",
    "    # Statistical tests\n",
    "    comparator.statistical_significance_test()\n",
    "    \n",
    "    # ========================================\n",
    "    # SAVE ALL RESULTS\n",
    "    # ========================================\n",
    "    \n",
    "    log_msg(\"\\n\" + \"=\"*80)\n",
    "    log_msg(\"SAVING RESULTS\")\n",
    "    log_msg(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Save evaluation results\n",
    "    with open(f\"{OUTPUT_DIR}/evaluation_results.json\", 'w') as f:\n",
    "        eval_serializable = {}\n",
    "        for enc_name, results in evaluation_results.items():\n",
    "            eval_serializable[enc_name] = {\n",
    "                'stability': results['stability'].to_dict('records'),\n",
    "                'redundancy': results['redundancy'],\n",
    "                'separability': results['separability']\n",
    "            }\n",
    "        json.dump(eval_serializable, f, indent=2)\n",
    "    \n",
    "    # Save comparison results\n",
    "    with open(f\"{OUTPUT_DIR}/comparison_results.json\", 'w') as f:\n",
    "        json.dump(comparison_results, f, indent=2)\n",
    "    \n",
    "    log_msg(\"✅ All results saved\")\n",
    "    \n",
    "    # ========================================\n",
    "    # PRINT SUMMARY\n",
    "    # ========================================\n",
    "    \n",
    "    log_msg(\"\\n\" + \"=\"*80)\n",
    "    log_msg(\"✅ COMPLETE PIPELINE WITH COMPARISON FINISHED\")\n",
    "    log_msg(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    log_msg(\"KEY FINDINGS:\")\n",
    "    log_msg(\"-\" * 80)\n",
    "    \n",
    "    # Find best performing method\n",
    "    best_stability = max(\n",
    "        [(k, v['stability_mean']) for k, v in comparison_results.items() \n",
    "         if v['stability_mean'] is not None],\n",
    "        key=lambda x: x[1]\n",
    "    )\n",
    "    log_msg(f\"Best Stability: {best_stability[0]} = {best_stability[1]:.3f}\")\n",
    "    \n",
    "    best_redundancy = min(\n",
    "        [(k, v['redundancy_ratio']) for k, v in comparison_results.items() \n",
    "         if v['redundancy_ratio'] is not None],\n",
    "        key=lambda x: x[1]\n",
    "    )\n",
    "    log_msg(f\"Best Redundancy (lowest): {best_redundancy[0]} = {best_redundancy[1]:.3f}\")\n",
    "    \n",
    "    if any(v['silhouette_score'] for v in comparison_results.values()):\n",
    "        best_separability = max(\n",
    "            [(k, v['silhouette_score']) for k, v in comparison_results.items() \n",
    "             if v['silhouette_score'] is not None],\n",
    "            key=lambda x: x[1]\n",
    "        )\n",
    "        log_msg(f\"Best Separability: {best_separability[0]} = {best_separability[1]:.3f}\")\n",
    "    \n",
    "    log_msg(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_with_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ffb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
