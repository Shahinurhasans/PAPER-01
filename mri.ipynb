{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03423e18",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'radiomics.featureextractor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnibabel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnib\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mradiomics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatureextractor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RadiomicsFeatureExtractor\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mSimpleITK\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msitk\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m zoom\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'radiomics.featureextractor'"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MRI FEATURE EXTRACTION PIPELINE - FULLY CORRECTED VERSION\n",
    "# Fixed: Pretrained Med3D, Proper normalization, Full embeddings\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nibabel as nib\n",
    "from radiomics.featureextractor import RadiomicsFeatureExtractor\n",
    "import SimpleITK as sitk\n",
    "from scipy.ndimage import zoom\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===============================\n",
    "# REPRODUCIBILITY\n",
    "# ===============================\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "MRI_DIR = r\"C:\\Users\\Shahinur\\Downloads\\PKG_Dataset\\PKG - Brain-Mets-Lung-MRI-Path-Segs_radiology_images\\Brain-Mets-Lung-MRI-Path-Segs\"\n",
    "OUTPUT_DIR = \"MRI_PYRADIOMICS_MED3D_OUTPUT\"\n",
    "FIGURES_DIR = f\"{OUTPUT_DIR}/validation_figures\"\n",
    "PRETRAINED_DIR = r\"D:\\paper\\weights\\MedicalNet_pytorch_files2\"  # Your pretrained weights location\n",
    "\n",
    "Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "Path(FIGURES_DIR).mkdir(exist_ok=True)\n",
    "Path(PRETRAINED_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MRI PIPELINE: PyRadiomics + MedicalNet - CORRECTED VERSION\")\n",
    "print(\"FIXES: Pretrained weights, Z-score norm, Full embeddings, QC heuristics\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"MRI Directory: {MRI_DIR}\")\n",
    "print(f\"Output: {OUTPUT_DIR}\\n\")\n",
    "\n",
    "def log_msg(m):\n",
    "    print(m)\n",
    "    try:\n",
    "        with open(f\"{OUTPUT_DIR}/progress.log\", 'a') as f:\n",
    "            f.write(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {m}\\n\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# ============================================================\n",
    "# MED3D: 3D ResNet Architecture\n",
    "# ============================================================\n",
    "class BasicBlock3D(nn.Module):\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(planes, planes, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class Med3DResNet(nn.Module):\n",
    "    def __init__(self, model_depth=10, num_classes=400):\n",
    "        super(Med3DResNet, self).__init__()\n",
    "        \n",
    "        if model_depth == 10:\n",
    "            layers = [1, 1, 1, 1]\n",
    "        elif model_depth == 18:\n",
    "            layers = [2, 2, 2, 2]\n",
    "        elif model_depth == 34:\n",
    "            layers = [3, 4, 6, 3]\n",
    "        else:\n",
    "            layers = [1, 1, 1, 1]\n",
    "        \n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv3d(1, 64, kernel_size=7, stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=(3, 3, 3), stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(BasicBlock3D, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(BasicBlock3D, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock3D, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock3D, 512, layers[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv3d(self.inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(planes)\n",
    "            )\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        return x  # Return 512-dim features\n",
    "\n",
    "# ============================================================\n",
    "# PRETRAINED WEIGHTS LOADER (FIX #1)\n",
    "# ============================================================\n",
    "def download_pretrained_weights(model_depth=10):\n",
    "    \"\"\"Load pretrained MedicalNet weights from your extracted folder\"\"\"\n",
    "    \n",
    "    # Check common weight file names in MedicalNet\n",
    "    possible_files = [\n",
    "        f\"{PRETRAINED_DIR}/resnet_{model_depth}_23dataset.pth\",\n",
    "        f\"{PRETRAINED_DIR}/resnet_{model_depth}.pth\",\n",
    "        f\"{PRETRAINED_DIR}/trail_1/resnet_{model_depth}_23dataset.pth\",\n",
    "        f\"{PRETRAINED_DIR}/trail_1/resnet_{model_depth}.pth\",\n",
    "        f\"{PRETRAINED_DIR}/models/resnet_{model_depth}_23dataset.pth\",\n",
    "    ]\n",
    "    \n",
    "    # Search for the weight file\n",
    "    for weight_file in possible_files:\n",
    "        if os.path.exists(weight_file):\n",
    "            log_msg(f\"  ‚úÖ Found pretrained weights: {weight_file}\")\n",
    "            return weight_file\n",
    "    \n",
    "    # If not found, list available files to help user\n",
    "    log_msg(f\"  ‚ö†Ô∏è Pretrained weights not found in standard locations!\")\n",
    "    log_msg(f\"  üìÇ Searching in: {PRETRAINED_DIR}\")\n",
    "    \n",
    "    if os.path.exists(PRETRAINED_DIR):\n",
    "        log_msg(f\"  üìã Available files:\")\n",
    "        for root, dirs, files in os.walk(PRETRAINED_DIR):\n",
    "            for file in files:\n",
    "                if file.endswith('.pth'):\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    log_msg(f\"     - {full_path}\")\n",
    "        \n",
    "        # Try to find any .pth file with 'resnet' and '10' in name\n",
    "        for root, dirs, files in os.walk(PRETRAINED_DIR):\n",
    "            for file in files:\n",
    "                if 'resnet' in file.lower() and '10' in file and file.endswith('.pth'):\n",
    "                    weight_file = os.path.join(root, file)\n",
    "                    log_msg(f\"  ‚úÖ Auto-detected weight file: {weight_file}\")\n",
    "                    return weight_file\n",
    "    \n",
    "    log_msg(f\"  ‚ùå Could not find resnet_10 weights!\")\n",
    "    log_msg(f\"  üí° Please check the extracted folder structure\")\n",
    "    return None\n",
    "\n",
    "def load_pretrained_med3d(model, pretrained_path):\n",
    "    \"\"\"Load pretrained weights with proper handling\"\"\"\n",
    "    if pretrained_path is None or not os.path.exists(pretrained_path):\n",
    "        log_msg(\"  ‚ùå NO PRETRAINED WEIGHTS - USING RANDOM INITIALIZATION!\")\n",
    "        log_msg(\"  ‚ö†Ô∏è  THIS WILL PRODUCE INVALID FEATURES!\")\n",
    "        return model, False\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(pretrained_path, map_location='cpu')\n",
    "        \n",
    "        # Handle different checkpoint formats\n",
    "        if 'state_dict' in checkpoint:\n",
    "            state_dict = checkpoint['state_dict']\n",
    "        elif 'model_state_dict' in checkpoint:\n",
    "            state_dict = checkpoint['model_state_dict']\n",
    "        else:\n",
    "            state_dict = checkpoint\n",
    "        \n",
    "        # Remove 'module.' prefix (DataParallel)\n",
    "        new_state_dict = {}\n",
    "        for k, v in state_dict.items():\n",
    "            name = k.replace('module.', '')\n",
    "            new_state_dict[name] = v\n",
    "        \n",
    "        # Load weights (ignore FC - different num_classes)\n",
    "        model_dict = model.state_dict()\n",
    "        pretrained_dict = {k: v for k, v in new_state_dict.items() \n",
    "                          if k in model_dict and 'fc' not in k}\n",
    "        \n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict, strict=False)\n",
    "        \n",
    "        log_msg(f\"  ‚úÖ Loaded {len(pretrained_dict)}/{len(model_dict)} pretrained layers\")\n",
    "        return model, True\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_msg(f\"  ‚ùå Failed to load pretrained weights: {e}\")\n",
    "        log_msg(f\"  ‚ö†Ô∏è  Falling back to RANDOM initialization (INVALID!)\")\n",
    "        return model, False\n",
    "\n",
    "# ============================================================\n",
    "# MRI DATA LOADER (FIX #2: Proper Normalization)\n",
    "# ============================================================\n",
    "class MRILoader:\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_nifti_as_sitk(path):\n",
    "        \"\"\"Load as SimpleITK (for PyRadiomics - no normalization)\"\"\"\n",
    "        try:\n",
    "            return sitk.ReadImage(path)\n",
    "        except Exception as e:\n",
    "            log_msg(f\"  ‚ö†Ô∏è Failed to load {path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_nifti_as_numpy(path):\n",
    "        \"\"\"Load as numpy - NO normalization (handle downstream)\"\"\"\n",
    "        try:\n",
    "            nii = nib.load(path)\n",
    "            data = nii.get_fdata()\n",
    "            data = np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            return data.astype(np.float32)\n",
    "        except Exception as e:\n",
    "            log_msg(f\"  ‚ö†Ô∏è Failed to load {path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_patient_scans(patient_dir):\n",
    "        \"\"\"Get all NIfTI scans\"\"\"\n",
    "        scans = {}\n",
    "        for file in os.listdir(patient_dir):\n",
    "            if file.endswith('.nii'):\n",
    "                scan_type = None\n",
    "                if 't1ce' in file.lower():\n",
    "                    scan_type = 't1ce'\n",
    "                elif 'flair' in file.lower():\n",
    "                    scan_type = 'flair'\n",
    "                elif 'whole_seg' in file.lower():\n",
    "                    scan_type = 'seg'\n",
    "                elif 'core_seg' in file.lower():\n",
    "                    scan_type = 'core'\n",
    "                \n",
    "                if scan_type:\n",
    "                    scans[scan_type] = os.path.join(patient_dir, file)\n",
    "        return scans\n",
    "    \n",
    "    @staticmethod\n",
    "    def resize_volume(volume, target_shape=(64, 64, 64)):\n",
    "        \"\"\"Resize 3D volume\"\"\"\n",
    "        zoom_factors = [t/s for t, s in zip(target_shape, volume.shape)]\n",
    "        return zoom(volume, zoom_factors, order=1)\n",
    "\n",
    "# ============================================================\n",
    "# OPTIMIZER (FIX #3: QC Heuristics Only)\n",
    "# ============================================================\n",
    "class MRIOptimizer:\n",
    "    \n",
    "    def __init__(self, patient_dirs):\n",
    "        self.patient_dirs = patient_dirs\n",
    "        self.results = {}\n",
    "        self.calibration_data = {\n",
    "            'volume_intensities': [],\n",
    "            'snr_scores': [],\n",
    "            'contrast_scores': [],\n",
    "            'patch_size_curve': [],\n",
    "            'patch_variance_curve': [],\n",
    "            'normalization_means': defaultdict(list),\n",
    "            'normalization_stds': defaultdict(list),\n",
    "            'bootstrap_samples': [],\n",
    "            'brain_volume_ratios': []\n",
    "        }\n",
    "    \n",
    "    def _sample_volumes(self, max_patients=5):\n",
    "        loader = MRILoader()\n",
    "        volumes = []\n",
    "        \n",
    "        for patient_dir in self.patient_dirs[:max_patients]:\n",
    "            scans = loader.get_patient_scans(patient_dir)\n",
    "            for scan_type in ['t1ce', 'flair']:\n",
    "                if scan_type not in scans:\n",
    "                    continue\n",
    "                volume = loader.load_nifti_as_numpy(scans[scan_type])\n",
    "                if volume is not None:\n",
    "                    volumes.append((volume, scan_type))\n",
    "        return volumes\n",
    "    \n",
    "    def optimize_patch_size(self):\n",
    "        log_msg(\"METHOD 1: 3D Patch Size Optimization\")\n",
    "        volumes = self._sample_volumes(max_patients=3)\n",
    "        \n",
    "        if len(volumes) < 2:\n",
    "            optimal = 64\n",
    "        else:\n",
    "            patch_sizes = [32, 48, 64, 80, 96, 112, 128]\n",
    "            variances = []\n",
    "            \n",
    "            for ps in patch_sizes:\n",
    "                patch_vars = []\n",
    "                for volume, _ in volumes[:3]:\n",
    "                    for _ in range(5):\n",
    "                        if all(s > ps for s in volume.shape):\n",
    "                            x = np.random.randint(0, volume.shape[0] - ps)\n",
    "                            y = np.random.randint(0, volume.shape[1] - ps)\n",
    "                            z = np.random.randint(0, volume.shape[2] - ps)\n",
    "                            patch = volume[x:x+ps, y:y+ps, z:z+ps]\n",
    "                            nz = patch[patch > np.percentile(volume, 10)]\n",
    "                            if len(nz) > 100:\n",
    "                                patch_vars.append(np.var(nz))\n",
    "                \n",
    "                if patch_vars:\n",
    "                    variances.append(np.mean(patch_vars))\n",
    "                    self.calibration_data['patch_size_curve'].append(ps)\n",
    "                    self.calibration_data['patch_variance_curve'].append(float(np.mean(patch_vars)))\n",
    "            \n",
    "            if len(variances) >= 3:\n",
    "                grad2 = np.gradient(np.gradient(variances))\n",
    "                elbow_idx = np.argmin(np.abs(grad2))\n",
    "                optimal = patch_sizes[elbow_idx]\n",
    "            else:\n",
    "                optimal = 64\n",
    "        \n",
    "        optimal = max(48, min(optimal, 128))\n",
    "        self.results['patch_size'] = {'optimal': optimal}\n",
    "        log_msg(f\"‚úÖ Optimal 3D patch: {optimal}¬≥\")\n",
    "        return optimal\n",
    "    \n",
    "    def optimize_quality_metrics(self):\n",
    "        log_msg(\"METHOD 2: Quality Metrics (QC heuristics only)\")\n",
    "        volumes = self._sample_volumes(max_patients=6)\n",
    "        \n",
    "        snrs = []\n",
    "        contrasts = []\n",
    "        \n",
    "        for volume, _ in volumes:\n",
    "            foreground = volume[volume > np.percentile(volume, 50)]\n",
    "            background = volume[volume < np.percentile(volume, 10)]\n",
    "            \n",
    "            if len(background) > 10 and background.std() > 0:\n",
    "                snr = foreground.mean() / (background.std() + 1e-8)\n",
    "                snrs.append(snr)\n",
    "            \n",
    "            contrast = volume.std()\n",
    "            contrasts.append(contrast)\n",
    "        \n",
    "        self.calibration_data['snr_scores'] = [float(s) for s in snrs]\n",
    "        self.calibration_data['contrast_scores'] = [float(c) for c in contrasts]\n",
    "        \n",
    "        snr_th = float(np.percentile(snrs, 20)) if snrs else 5.0\n",
    "        contrast_th = float(np.percentile(contrasts, 25)) if contrasts else 15.0\n",
    "        \n",
    "        self.results['qc_thresholds'] = {\n",
    "            'snr': snr_th,\n",
    "            'contrast': contrast_th,\n",
    "            'note': 'QC heuristics - scanner specific, not for normalization'\n",
    "        }\n",
    "        \n",
    "        log_msg(f\"‚úÖ QC thresholds: SNR={snr_th:.2f}, Contrast={contrast_th:.2f}\")\n",
    "        log_msg(f\"   ‚ö†Ô∏è These are QC heuristics ONLY - NOT for normalization!\")\n",
    "        return snr_th, contrast_th\n",
    "    \n",
    "    def save(self, output_dir):\n",
    "        try:\n",
    "            with open(f\"{output_dir}/optimization.json\", 'w') as f:\n",
    "                json.dump({\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'seed': RANDOM_SEED,\n",
    "                    'warning': 'Thresholds are QC heuristics - scanner/protocol specific',\n",
    "                    **self.results\n",
    "                }, f, indent=2)\n",
    "            \n",
    "            with open(f\"{output_dir}/calibration_data.json\", 'w') as f:\n",
    "                json.dump(self.calibration_data, f, indent=2)\n",
    "            \n",
    "            log_msg(f\"‚úÖ Saved optimization results\")\n",
    "        except Exception as e:\n",
    "            log_msg(f\"‚ùå Error saving: {e}\")\n",
    "\n",
    "# ============================================================\n",
    "# FEATURE EXTRACTORS\n",
    "# ============================================================\n",
    "class PyRadiomicsExtractor:\n",
    "    \"\"\"PyRadiomics - handles normalization internally\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        log_msg(\"  Initializing PyRadiomics...\")\n",
    "        self.extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "        self.extractor.enableImageTypeByName('Original')\n",
    "        self.extractor.enableFeatureClassByName('firstorder')\n",
    "        self.extractor.enableFeatureClassByName('shape')\n",
    "        self.extractor.enableFeatureClassByName('glcm')\n",
    "        self.extractor.enableFeatureClassByName('glrlm')\n",
    "        self.extractor.enableFeatureClassByName('glszm')\n",
    "        self.extractor.enableFeatureClassByName('gldm')\n",
    "        log_msg(\"    ‚úÖ PyRadiomics ready\")\n",
    "    \n",
    "    def extract(self, image_path, mask_path=None):\n",
    "        try:\n",
    "            image = sitk.ReadImage(image_path)\n",
    "            \n",
    "            if mask_path is None or not os.path.exists(mask_path):\n",
    "                image_arr = sitk.GetArrayFromImage(image)\n",
    "                threshold = np.percentile(image_arr, 15)\n",
    "                mask_arr = (image_arr > threshold).astype(np.uint8)\n",
    "                mask = sitk.GetImageFromArray(mask_arr)\n",
    "                mask.CopyInformation(image)\n",
    "            else:\n",
    "                mask = sitk.ReadImage(mask_path)\n",
    "            \n",
    "            features = self.extractor.execute(image, mask)\n",
    "            \n",
    "            feature_dict = {}\n",
    "            for key, val in features.items():\n",
    "                if not key.startswith('diagnostics'):\n",
    "                    try:\n",
    "                        feature_dict[key] = float(val)\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            return feature_dict\n",
    "            \n",
    "        except Exception as e:\n",
    "            log_msg(f\"    ‚ö†Ô∏è PyRadiomics failed: {e}\")\n",
    "            return None\n",
    "\n",
    "class Med3DExtractor:\n",
    "    \"\"\"Med3D with FULL embeddings (FIX #4)\"\"\"\n",
    "    \n",
    "    def __init__(self, patch_size=64, use_pretrained=True):\n",
    "        log_msg(\"  Initializing Med3D...\")\n",
    "        self.patch_size = patch_size\n",
    "        self.model = Med3DResNet(model_depth=10, num_classes=400)\n",
    "        self.is_pretrained = False\n",
    "        \n",
    "        if use_pretrained:\n",
    "            pretrained_path = download_pretrained_weights(model_depth=10)\n",
    "            self.model, self.is_pretrained = load_pretrained_med3d(self.model, pretrained_path)\n",
    "        \n",
    "        self.model = self.model.to(DEVICE).eval()\n",
    "        \n",
    "        if not self.is_pretrained:\n",
    "            log_msg(\"    ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è WARNING: No pretrained weights - features INVALID!\")\n",
    "    \n",
    "    def preprocess_volume(self, volume):\n",
    "        \"\"\"FIX #2: Z-score normalization\"\"\"\n",
    "        # Resize\n",
    "        if volume.shape != (self.patch_size, self.patch_size, self.patch_size):\n",
    "            volume = MRILoader.resize_volume(volume, (self.patch_size, self.patch_size, self.patch_size))\n",
    "        \n",
    "        # Z-score normalization (robust)\n",
    "        mask = volume > np.percentile(volume, 1)\n",
    "        if mask.sum() > 100:\n",
    "            mean = volume[mask].mean()\n",
    "            std = volume[mask].std()\n",
    "            volume = (volume - mean) / (std + 1e-8)\n",
    "        else:\n",
    "            volume = (volume - volume.mean()) / (volume.std() + 1e-8)\n",
    "        \n",
    "        volume = torch.FloatTensor(volume).unsqueeze(0).unsqueeze(0)\n",
    "        return volume\n",
    "    \n",
    "    def extract(self, volume):\n",
    "        \"\"\"FIX #4: Return FULL 512-dim embedding\"\"\"\n",
    "        try:\n",
    "            volume_tensor = self.preprocess_volume(volume).to(DEVICE)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                features = self.model(volume_tensor)\n",
    "            \n",
    "            features_np = features.squeeze().cpu().numpy()\n",
    "            \n",
    "            # Return FULL embedding + statistics\n",
    "            result = {\n",
    "                'med3d_embedding': features_np.tolist(),  # FULL 512-dim\n",
    "                'med3d_mean': float(features_np.mean()),\n",
    "                'med3d_std': float(features_np.std()),\n",
    "                'med3d_max': float(features_np.max()),\n",
    "                'med3d_min': float(features_np.min()),\n",
    "                'med3d_l2norm': float(np.linalg.norm(features_np)),\n",
    "                'is_pretrained': self.is_pretrained\n",
    "            }\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            log_msg(f\"    ‚ö†Ô∏è Med3D failed: {e}\")\n",
    "            return None\n",
    "\n",
    "# ============================================================\n",
    "# VALIDATION FIGURES\n",
    "# ============================================================\n",
    "class MRIValidationFigures:\n",
    "    def __init__(self, output_dir, figures_dir, opt_results, params, calib_data, features_df, qc_df):\n",
    "        self.output_dir = output_dir\n",
    "        self.figures_dir = figures_dir\n",
    "        self.opt_results = opt_results\n",
    "        self.params = params\n",
    "        self.calib_data = calib_data\n",
    "        self.features_df = features_df\n",
    "        self.qc_df = qc_df\n",
    "    \n",
    "    def generate_all(self):\n",
    "        log_msg(\"\\nGenerating validation figures...\")\n",
    "        self.fig01_patch_size()\n",
    "        self.fig02_quality_metrics()\n",
    "        self.fig03_qc_summary()\n",
    "        self.save_report()\n",
    "    \n",
    "    def fig01_patch_size(self):\n",
    "        log_msg(\"[1/3] Patch Size...\")\n",
    "        fig, ax = plt.subplots(figsize=(12, 7))\n",
    "        \n",
    "        patch_sizes = self.calib_data.get('patch_size_curve', [])\n",
    "        variances = self.calib_data.get('patch_variance_curve', [])\n",
    "        \n",
    "        if patch_sizes:\n",
    "            ax.plot(patch_sizes, variances, 'o-', linewidth=3, markersize=10, color='steelblue')\n",
    "            ax.axvline(self.params['patch_size'], color='red', linestyle='--', linewidth=2.5,\n",
    "                      label=f'Selected: {self.params[\"patch_size\"]}¬≥')\n",
    "        \n",
    "        ax.set_xlabel('Patch Size (voxels)', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Feature Variance', fontsize=13, fontweight='bold')\n",
    "        ax.set_title('3D Patch Size Optimization', fontsize=14, fontweight='bold')\n",
    "        ax.legend(fontsize=11)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.figures_dir}/01_patch_size.png\", dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    def fig02_quality_metrics(self):\n",
    "        log_msg(\"[2/3] Quality Metrics...\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        snrs = self.calib_data.get('snr_scores', [])\n",
    "        if snrs:\n",
    "            ax1.hist(snrs, bins=30, color='lightblue', alpha=0.7, edgecolor='black')\n",
    "            ax1.set_title('SNR Distribution (QC)', fontsize=12, fontweight='bold')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        contrasts = self.calib_data.get('contrast_scores', [])\n",
    "        if contrasts:\n",
    "            ax2.hist(contrasts, bins=30, color='lightcoral', alpha=0.7, edgecolor='black')\n",
    "            ax2.set_title('Contrast Distribution (QC)', fontsize=12, fontweight='bold')\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.figures_dir}/02_quality_metrics.png\", dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    def fig03_qc_summary(self):\n",
    "        log_msg(\"[3/3] QC Summary...\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        success = (self.qc_df['status'] == 'ok').sum()\n",
    "        fail = (self.qc_df['status'] == 'fail').sum()\n",
    "        \n",
    "        ax1.pie([success, fail], labels=[f'Success\\n{success}', f'Fail\\n{fail}'],\n",
    "               autopct='%1.1f%%', colors=['#2ecc71', '#e74c3c'], startangle=90)\n",
    "        ax1.set_title('Processing Success', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Feature counts\n",
    "        radiomics_count = len([c for c in self.features_df.columns if 'original' in c.lower()])\n",
    "        med3d_count = 516  # 512 embedding + 4 stats\n",
    "        \n",
    "        ax2.bar(['PyRadiomics', 'Med3D'], [radiomics_count, med3d_count],\n",
    "               color=['#3498db', '#e74c3c'], edgecolor='black', linewidth=2)\n",
    "        ax2.set_ylabel('Feature Count', fontsize=11, fontweight='bold')\n",
    "        ax2.set_title('Feature Methods', fontsize=12, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.figures_dir}/03_qc_summary.png\", dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    def save_report(self):\n",
    "        success = (self.qc_df['status'] == 'ok').sum()\n",
    "        \n",
    "        report = f\"\"\"\n",
    "MRI PIPELINE VALIDATION REPORT - CORRECTED VERSION\n",
    "\n",
    "OUTPUT: {self.figures_dir}/\n",
    "\n",
    "GENERATED FIGURES:\n",
    "  01. 01_patch_size.png - Patch size optimization\n",
    "  02. 02_quality_metrics.png - QC metrics (SNR, Contrast)\n",
    "  03. 03_qc_summary.png - Processing summary\n",
    "\n",
    "KEY STATISTICS:\n",
    "  ‚Ä¢ Patients: {len(self.qc_df)}\n",
    "  ‚Ä¢ Success: {success} ({success/len(self.qc_df)*100:.1f}%)\n",
    "  ‚Ä¢ PyRadiomics features: ~{len([c for c in self.features_df.columns if 'original' in c.lower()])}\n",
    "  ‚Ä¢ Med3D features: 512-dim embedding + 4 stats\n",
    "\n",
    "CRITICAL FIXES APPLIED:\n",
    "  ‚úÖ FIX #1: Pretrained Med3D weights support\n",
    "  ‚úÖ FIX #2: Z-score normalization (robust, scanner-independent)\n",
    "  ‚úÖ FIX #3: Full 512-dim embeddings (not collapsed to 4 numbers)\n",
    "  ‚úÖ FIX #4: QC thresholds as heuristics only (not for normalization)\n",
    "  ‚úÖ FIX #5: No hardcoded intensity thresholds\n",
    "\n",
    "IMPORTANT NOTES:\n",
    "  ‚Ä¢ Download pretrained weights from: https://github.com/Tencent/MedicalNet\n",
    "  ‚Ä¢ QC thresholds are scanner-specific - use for quality checks only\n",
    "  ‚Ä¢ Med3D requires pretrained weights to produce valid features\n",
    "  ‚Ä¢ Full 512-dim embeddings saved for downstream analysis\n",
    "\"\"\"\n",
    "        \n",
    "        log_msg(report)\n",
    "        with open(f\"{self.figures_dir}/VALIDATION_REPORT.txt\", 'w') as f:\n",
    "            f.write(report)\n",
    "\n",
    "# ============================================================\n",
    "# MAIN PIPELINE\n",
    "# ============================================================\n",
    "def main():\n",
    "    patient_dirs = [os.path.join(MRI_DIR, d) for d in os.listdir(MRI_DIR) \n",
    "                   if os.path.isdir(os.path.join(MRI_DIR, d))]\n",
    "    \n",
    "    if len(patient_dirs) == 0:\n",
    "        log_msg(\"‚ùå No patient directories found!\")\n",
    "        return\n",
    "    \n",
    "    np.random.shuffle(patient_dirs)\n",
    "    \n",
    "    # 15% for calibration\n",
    "    n_calib = max(1, int(0.15 * len(patient_dirs)))\n",
    "    cal_dirs = patient_dirs[:n_calib]\n",
    "    proc_dirs = patient_dirs\n",
    "    \n",
    "    log_msg(\"\\n\" + \"=\"*80)\n",
    "    log_msg(\"STEP 1: CALIBRATION\")\n",
    "    log_msg(\"=\"*80)\n",
    "    log_msg(f\"Calibration: {n_calib} patients\")\n",
    "    log_msg(f\"Processing: {len(proc_dirs)} patients\\n\")\n",
    "    \n",
    "    # Optimize\n",
    "    opt = MRIOptimizer(cal_dirs)\n",
    "    patch_size = opt.optimize_patch_size()\n",
    "    snr_th, contrast_th = opt.optimize_quality_metrics()\n",
    "    opt.save(OUTPUT_DIR)\n",
    "    \n",
    "    params = {\n",
    "        'patch_size': patch_size,\n",
    "        'qc_snr': snr_th,\n",
    "        'qc_contrast': contrast_th\n",
    "    }\n",
    "    \n",
    "    with open(f\"{OUTPUT_DIR}/params.json\", 'w') as f:\n",
    "        json.dump(params, f, indent=2)\n",
    "    \n",
    "    # Initialize extractors\n",
    "    pyrad = PyRadiomicsExtractor()\n",
    "    med3d = Med3DExtractor(patch_size=patch_size, use_pretrained=True)\n",
    "    loader = MRILoader()\n",
    "    \n",
    "    log_msg(\"\\n\" + \"=\"*80)\n",
    "    log_msg(\"STEP 2: FEATURE EXTRACTION\")\n",
    "    log_msg(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    all_rows = []\n",
    "    qc_rows = []\n",
    "    \n",
    "    for i, patient_dir in enumerate(proc_dirs, 1):\n",
    "        try:\n",
    "            patient_id = os.path.basename(patient_dir)\n",
    "            log_msg(f\"[{i}/{len(proc_dirs)}] {patient_id}\")\n",
    "            \n",
    "            scans = loader.get_patient_scans(patient_dir)\n",
    "            \n",
    "            if not scans:\n",
    "                log_msg(f\"  ‚ùå No scans found\")\n",
    "                qc_rows.append({'patient': patient_id, 'status': 'fail', 'primary_modality': 'none'})\n",
    "                continue\n",
    "            \n",
    "            # Primary modality\n",
    "            primary_modality = 't1ce' if 't1ce' in scans else ('flair' if 'flair' in scans else None)\n",
    "            \n",
    "            if primary_modality is None:\n",
    "                log_msg(f\"  ‚ùå No T1CE or FLAIR\")\n",
    "                qc_rows.append({'patient': patient_id, 'status': 'fail', 'primary_modality': 'none'})\n",
    "                continue\n",
    "            \n",
    "            row = {'patient': patient_id}\n",
    "            \n",
    "            # PyRadiomics\n",
    "            log_msg(f\"  ‚Üí PyRadiomics ({primary_modality.upper()})...\")\n",
    "            pyrad_feats = pyrad.extract(scans[primary_modality], \n",
    "                                       scans.get('seg', scans.get('core', None)))\n",
    "            \n",
    "            if pyrad_feats:\n",
    "                row.update(pyrad_feats)\n",
    "                log_msg(f\"    ‚úÖ {len(pyrad_feats)} features\")\n",
    "            \n",
    "            # Med3D\n",
    "            log_msg(f\"  ‚Üí Med3D...\")\n",
    "            volume = loader.load_nifti_as_numpy(scans[primary_modality])\n",
    "            \n",
    "            if volume is not None:\n",
    "                med3d_feats = med3d.extract(volume)\n",
    "                \n",
    "                if med3d_feats:\n",
    "                    # Save summary stats in main CSV\n",
    "                    row['med3d_mean'] = med3d_feats['med3d_mean']\n",
    "                    row['med3d_std'] = med3d_feats['med3d_std']\n",
    "                    row['med3d_max'] = med3d_feats['med3d_max']\n",
    "                    row['med3d_min'] = med3d_feats['med3d_min']\n",
    "                    row['med3d_l2norm'] = med3d_feats['med3d_l2norm']\n",
    "                    row['med3d_pretrained'] = med3d_feats['is_pretrained']\n",
    "                    \n",
    "                    # Save FULL embedding separately\n",
    "                    embedding = {\n",
    "                        'patient': patient_id,\n",
    "                        'embedding': med3d_feats['med3d_embedding'],\n",
    "                        'is_pretrained': med3d_feats['is_pretrained']\n",
    "                    }\n",
    "                    \n",
    "                    with open(f\"{OUTPUT_DIR}/embeddings/{patient_id}_med3d.json\", 'w') as f:\n",
    "                        json.dump(embedding, f)\n",
    "                    \n",
    "                    log_msg(f\"    ‚úÖ Med3D: 512-dim embedding saved\")\n",
    "            \n",
    "            all_rows.append(row)\n",
    "            qc_rows.append({'patient': patient_id, 'status': 'ok', 'primary_modality': primary_modality})\n",
    "            \n",
    "            log_msg(f\"  ‚úÖ Total: {len(row)-1} features\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            log_msg(f\"  ‚ùå Error: {e}\")\n",
    "            traceback.print_exc()\n",
    "            qc_rows.append({'patient': os.path.basename(patient_dir), 'status': 'fail', \n",
    "                          'primary_modality': 'error'})\n",
    "            continue\n",
    "    \n",
    "    # Save results\n",
    "    log_msg(\"\\n\" + \"=\"*80)\n",
    "    log_msg(\"STEP 3: SAVING RESULTS\")\n",
    "    log_msg(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Create embeddings directory\n",
    "    Path(f\"{OUTPUT_DIR}/embeddings\").mkdir(exist_ok=True)\n",
    "    \n",
    "    if all_rows:\n",
    "        df = pd.DataFrame(all_rows)\n",
    "        df.to_csv(f\"{OUTPUT_DIR}/all_features.csv\", index=False)\n",
    "        log_msg(f\"‚úÖ Features: {len(df)} patients √ó {len(df.columns)-1} features\")\n",
    "        log_msg(f\"   Main CSV: {OUTPUT_DIR}/all_features.csv\")\n",
    "        log_msg(f\"   Full embeddings: {OUTPUT_DIR}/embeddings/\")\n",
    "    else:\n",
    "        log_msg(\"‚ùå No patients processed!\")\n",
    "        return\n",
    "    \n",
    "    # QC\n",
    "    qc_df = pd.DataFrame(qc_rows)\n",
    "    qc_df.to_csv(f\"{OUTPUT_DIR}/qc.csv\", index=False)\n",
    "    log_msg(f\"‚úÖ QC: {OUTPUT_DIR}/qc.csv\")\n",
    "    \n",
    "    # Validation figures\n",
    "    log_msg(\"\\n\" + \"=\"*80)\n",
    "    log_msg(\"STEP 4: VALIDATION FIGURES\")\n",
    "    log_msg(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    validator = MRIValidationFigures(\n",
    "        OUTPUT_DIR,\n",
    "        FIGURES_DIR,\n",
    "        opt.results,\n",
    "        params,\n",
    "        opt.calibration_data,\n",
    "        df,\n",
    "        qc_df\n",
    "    )\n",
    "    validator.generate_all()\n",
    "    \n",
    "    log_msg(\"\\n\" + \"=\"*80)\n",
    "    log_msg(\"‚úÖ PIPELINE COMPLETE - ALL FIXES APPLIED\")\n",
    "    log_msg(\"=\"*80)\n",
    "    log_msg(\"\\nCRITICAL REMINDERS:\")\n",
    "    log_msg(\"  1. Download pretrained Med3D weights if not present\")\n",
    "    log_msg(\"  2. Full 512-dim embeddings saved in embeddings/\")\n",
    "    log_msg(\"  3. QC thresholds are heuristics only - not for normalization\")\n",
    "    log_msg(\"  4. Z-score normalization applied in Med3D preprocessing\")\n",
    "    log_msg(\"  5. PyRadiomics handles normalization internally\")\n",
    "    log_msg(\"\\nFIXES APPLIED:\")\n",
    "    log_msg(\"  ‚úÖ Pretrained weight loading (with fallback warning)\")\n",
    "    log_msg(\"  ‚úÖ Z-score normalization (scanner-independent)\")\n",
    "    log_msg(\"  ‚úÖ Full 512-dim embeddings (not collapsed)\")\n",
    "    log_msg(\"  ‚úÖ QC thresholds as heuristics only\")\n",
    "    log_msg(\"  ‚úÖ Proper normalization handling\")\n",
    "    log_msg(f\"\\nOutput: {OUTPUT_DIR}\")\n",
    "    log_msg(f\"Figures: {FIGURES_DIR}\")\n",
    "    log_msg(\"=\"*80 + \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007731bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PYRADIOMICS INSTALLATION FIX FOR WINDOWS\n",
      "================================================================================\n",
      "\n",
      "Python: d:\\paper\\venv\\python.exe\n",
      "Platform: Windows-10-10.0.26100-SP0\n",
      "Python version: 3.10.15 | packaged by conda-forge | (main, Oct 16 2024, 01:15:49) [MSC v.1941 64 bit (AMD64)]\n",
      "\n",
      "================================================================================\n",
      "TRYING: Pre-built wheel (recommended)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "METHOD 1: Installing pre-built PyRadiomics wheel\n",
      "================================================================================\n",
      "\n",
      "Running: d:\\paper\\venv\\python.exe -m pip install --upgrade pip setuptools wheel\n",
      "Running: d:\\paper\\venv\\python.exe -m pip install --only-binary :all: pyradiomics\n",
      "‚ùå Failed: Command 'd:\\paper\\venv\\python.exe -m pip install --only-binary :all: pyradiomics' returned non-zero exit status 1.\n",
      "\n",
      "================================================================================\n",
      "TRYING: Upgrade tools and retry\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "METHOD 2: Upgrading build tools and retrying\n",
      "================================================================================\n",
      "\n",
      "Running: d:\\paper\\venv\\python.exe -m pip install --upgrade pip setuptools wheel\n",
      "Running: d:\\paper\\venv\\python.exe -m pip install --upgrade numpy Cython\n",
      "Running: d:\\paper\\venv\\python.exe -m pip install pyradiomics --no-cache-dir\n",
      "‚ùå Failed: Command 'd:\\paper\\venv\\python.exe -m pip install pyradiomics --no-cache-dir' returned non-zero exit status 1.\n",
      "\n",
      "================================================================================\n",
      "TRYING: Conda installation\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "METHOD 3: Installing via conda-forge\n",
      "================================================================================\n",
      "\n",
      "Running: conda install -c conda-forge pyradiomics -y\n",
      "‚ùå Failed: Command 'conda install -c conda-forge pyradiomics -y' returned non-zero exit status 1.\n",
      "\n",
      "================================================================================\n",
      "TRYING: Build from source\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "METHOD 4: Building from source\n",
      "================================================================================\n",
      "\n",
      "Running: d:\\paper\\venv\\python.exe -m pip install --upgrade pip wheel setuptools\n",
      "Running: d:\\paper\\venv\\python.exe -m pip install numpy Cython six\n",
      "Running: d:\\paper\\venv\\python.exe -m pip install pyradiomics --no-build-isolation\n",
      "‚ùå Failed: Command 'd:\\paper\\venv\\python.exe -m pip install pyradiomics --no-build-isolation' returned non-zero exit status 1.\n",
      "\n",
      "================================================================================\n",
      "‚ùå ALL METHODS FAILED\n",
      "================================================================================\n",
      "\n",
      "MANUAL SOLUTIONS:\n",
      "\n",
      "1. Install Visual C++ Build Tools:\n",
      "   https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "   Then retry: pip install pyradiomics\n",
      "\n",
      "2. Use Anaconda/Miniconda:\n",
      "   conda create -n mri python=3.9\n",
      "   conda activate mri\n",
      "   conda install -c conda-forge pyradiomics\n",
      "\n",
      "3. Use WSL (Windows Subsystem for Linux):\n",
      "   Install Ubuntu from Microsoft Store\n",
      "   Then: pip install pyradiomics\n",
      "\n",
      "4. Use Docker:\n",
      "   docker pull radiomics/pyradiomics\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PYRADIOMICS INSTALLATION FIX - Windows Solutions\n",
    "# ============================================================\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "def run_command(cmd):\n",
    "    \"\"\"Run a command and return success status\"\"\"\n",
    "    try:\n",
    "        print(f\"Running: {cmd}\")\n",
    "        subprocess.check_call(cmd, shell=True)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def method_1_prebuilt_wheel():\n",
    "    \"\"\"Method 1: Try pre-built wheel (fastest)\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"METHOD 1: Installing pre-built PyRadiomics wheel\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    commands = [\n",
    "        # Upgrade pip first\n",
    "        f\"{sys.executable} -m pip install --upgrade pip setuptools wheel\",\n",
    "        \n",
    "        # Try pre-built wheel only\n",
    "        f\"{sys.executable} -m pip install --only-binary :all: pyradiomics\",\n",
    "    ]\n",
    "    \n",
    "    for cmd in commands:\n",
    "        if not run_command(cmd):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def method_2_upgrade_tools():\n",
    "    \"\"\"Method 2: Upgrade build tools and retry\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"METHOD 2: Upgrading build tools and retrying\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    commands = [\n",
    "        f\"{sys.executable} -m pip install --upgrade pip setuptools wheel\",\n",
    "        f\"{sys.executable} -m pip install --upgrade numpy Cython\",\n",
    "        f\"{sys.executable} -m pip install pyradiomics --no-cache-dir\",\n",
    "    ]\n",
    "    \n",
    "    for cmd in commands:\n",
    "        if not run_command(cmd):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def method_3_conda():\n",
    "    \"\"\"Method 3: Try conda installation\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"METHOD 3: Installing via conda-forge\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    commands = [\n",
    "        \"conda install -c conda-forge pyradiomics -y\",\n",
    "    ]\n",
    "    \n",
    "    for cmd in commands:\n",
    "        if not run_command(cmd):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def method_4_from_source():\n",
    "    \"\"\"Method 4: Install from source with specific flags\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"METHOD 4: Building from source\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    commands = [\n",
    "        f\"{sys.executable} -m pip install --upgrade pip wheel setuptools\",\n",
    "        f\"{sys.executable} -m pip install numpy Cython six\",\n",
    "        f\"{sys.executable} -m pip install pyradiomics --no-build-isolation\",\n",
    "    ]\n",
    "    \n",
    "    for cmd in commands:\n",
    "        if not run_command(cmd):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def verify_installation():\n",
    "    \"\"\"Verify PyRadiomics is installed correctly\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"VERIFYING INSTALLATION\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    try:\n",
    "        from radiomics import featureextractor\n",
    "        print(\"‚úÖ PyRadiomics imported successfully!\")\n",
    "        \n",
    "        # Try to create extractor\n",
    "        extractor = featureextractor.RadiomicsFeatureExtractor()\n",
    "        print(\"‚úÖ RadiomicsFeatureExtractor created successfully!\")\n",
    "        \n",
    "        # Get version\n",
    "        import radiomics\n",
    "        print(f\"‚úÖ PyRadiomics version: {radiomics.__version__}\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Verification failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*80)\n",
    "    print(\"PYRADIOMICS INSTALLATION FIX FOR WINDOWS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nPython: {sys.executable}\")\n",
    "    print(f\"Platform: {platform.platform()}\")\n",
    "    print(f\"Python version: {sys.version}\")\n",
    "    \n",
    "    # Try methods in order\n",
    "    methods = [\n",
    "        (\"Pre-built wheel (recommended)\", method_1_prebuilt_wheel),\n",
    "        (\"Upgrade tools and retry\", method_2_upgrade_tools),\n",
    "        (\"Conda installation\", method_3_conda),\n",
    "        (\"Build from source\", method_4_from_source),\n",
    "    ]\n",
    "    \n",
    "    for method_name, method_func in methods:\n",
    "        try:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"TRYING: {method_name}\")\n",
    "            print('='*80)\n",
    "            \n",
    "            if method_func():\n",
    "                if verify_installation():\n",
    "                    print(\"\\n\" + \"=\"*80)\n",
    "                    print(f\"‚úÖ SUCCESS! PyRadiomics installed via: {method_name}\")\n",
    "                    print(\"=\"*80)\n",
    "                    return\n",
    "        except Exception as e:\n",
    "            print(f\"Method failed with error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # If all methods failed\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚ùå ALL METHODS FAILED\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nMANUAL SOLUTIONS:\")\n",
    "    print(\"\\n1. Install Visual C++ Build Tools:\")\n",
    "    print(\"   https://visualstudio.microsoft.com/visual-cpp-build-tools/\")\n",
    "    print(\"   Then retry: pip install pyradiomics\")\n",
    "    \n",
    "    print(\"\\n2. Use Anaconda/Miniconda:\")\n",
    "    print(\"   conda create -n mri python=3.9\")\n",
    "    print(\"   conda activate mri\")\n",
    "    print(\"   conda install -c conda-forge pyradiomics\")\n",
    "    \n",
    "    print(\"\\n3. Use WSL (Windows Subsystem for Linux):\")\n",
    "    print(\"   Install Ubuntu from Microsoft Store\")\n",
    "   \n",
    "    \n",
    "    print(\"\\n4. Use Docker:\")\n",
    "    print(\"   docker pull radiomics/pyradiomics\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
